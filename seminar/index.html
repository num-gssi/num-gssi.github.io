<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../img/favicon.ico">

    
    <title>Seminars - CompMath @ GSSI</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../css/base.min.css" rel="stylesheet">
    <link href="../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    
    <link href="../css/extra.css" rel="stylesheet">
    <link href="http://tikzjax.com/v1/fonts.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/styles/default.min.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="..">CompMath @ GSSI</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li >
                        <a href="../people/">People</a>
                    </li>
                
                
                
                    <li class="active">
                        <a href="./">Seminars</a>
                    </li>
                
                
                
                    <li >
                        <a href="../reading_group/">Reading Group</a>
                    </li>
                
                
                
                    <li >
                        <a href="../calendar/">Calendar</a>
                    </li>
                
                
                
                    <li >
                        <a href="../venues/">Venues</a>
                    </li>
                
                
                
                    <li >
                        <a href="../pictures/">Pictures</a>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../people/">
                            <i class="fas fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="next" href="../reading_group/">
                            Next <i class="fas fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-12" role="main">

<h1 id="nomads-seminars">NOMADS Seminars</h1>
<p>We organize seminars in <strong>Numerical ODEs, Matrix Analysis and Data Science.</strong></p>
<p>The seminars focus on various topics in numerical analysis, numerical linear algebra, scientific computing and matrix theory with particular emphasis on their application in control theory, network science, data mining and machine learning.</p>
<p>Questions or comments about the seminars should be sent to <a href="https://www.gssi.it/people/professors/lectures-maths/item/545-guglielmi-nicola">Nicola Guglielmi</a> or <a href="https://ftudisco.gitlab.io">Francesco Tudisco</a>. 
 <br></p>
<h3 id="academic-year-202425">Academic Year 2024/25</h3>
<table>
<thead>
<tr>
<th>Speaker</th>
<th></th>
<th>Title, Abstract &amp; Other Info</th>
<th>Date &amp; Venue</th>
</tr>
</thead>
<tbody>
<tr>
<td><img style="width:60px;" src="https://media.licdn.com/dms/image/v2/D4E03AQHIlJ9ztp76eA/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1706354462973?e=2147483647&v=beta&t=bt12o3uacmKOup0q4j_ml6vbwf1GnzP88B8jRtpauxE"></td>
<td><a href="https://davidemurari.com/">Davide Murari</a><br> University of Cambridge, United Kingdom</td>
<td><strong>Symplectic Neural Flows for Modelling and Discovery</strong> <br><br> The Hamiltonian formalism offers a robust framework for describing many dynamical systems that conserve energy. In a Hamiltonian system, the flow preserves a volume form, a symplectic form, and the Hamiltonian energy. This talk focuses on canonical Hamiltonian systems in Euclidean spaces. We introduce a symplectic neural network designed to approximate the flow map of a given Hamiltonian system. Our architecture exhibits enhanced long-term behaviour compared to unconstrained alternatives, even though both methods perform similarly over short intervals. We also apply the proposed method to data-driven tasks, demonstrating its efficacy in approximating the flow map of unknown Hamiltonian systems. <br><br><a href="https://drive.google.com/file/d/1lUCb_SIMiS34ZTPM58sRXkfDntzpFreL/view?usp=drive_link">Slides of the talk</a></td>
<td>April 14, 2025 <br><br> 3:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.unige.ch/~hairer/pictures/hai07-2.jpg"></td>
<td><a href="https://www.unige.ch/~hairer/">Ernst Hairer</a><br> University of Geneva, Switzerland</td>
<td><strong>Interpolation preservation of AMF-W methods for linear diffusion problems</strong> <br><br> This talk considers the numerical integration of linear diffusion problems in high space dimension by AMF-W methods. These are methods of the type ADI (alternating direction implicit). We focus on the treatment of general Dirichlet boundary conditions. New is the introduction of a property -- interpolation preservation -- which permits to extend convergence results for homogeneous boundary conditions to general time-dependent boundary conditions. Numerical experiments confirm the theoretical results. <br> This talk is based on joint-work with Severiano González-Pinto and Domingo Hernández Abreu of the University of La Laguna, Spain.</td>
<td>April 8, 2025 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Library, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.maths.ox.ac.uk/system/files/styles/profile/private/users/photos/IMGb_0.jpg?h=3fb51373&itok=TZ1fsglZ"></td>
<td><a href="https://people.maths.ox.ac.uk/nakatsukasa/">Yuji Nakatsukasa</a><br> University of Oxford, United Kingdom</td>
<td><strong>Randomised algorithms in numerical linear algebra and the column subset selection problem</strong> <br><br> Randomisation is among the most exciting developments in numerical linear algebra, and has led to algorithms that are fast, scalable, robust, and reliable. The column subset selection problem (CSSP) is simple to state but not easy to solve, and has far-reaching consequences in a number of applications in computational mathematics. Several randomised and deterministic algorithms are now available for the CSSP. In this talk we will review a few prominent topics in randomised NLA (low-rank approximation, least-squares problems, norm/trace estimation). We will then explore the CSSP from computational and theoretical viewpoints, highlighting their power in practical applications. <br><br> <a href="https://drive.google.com/file/d/1N6JSt3wDuwrazQ3CVqujoAZtta52fCyi/view?usp=drive_link">Recording of the talk (available to GSSI only)</a></td>
<td>February 20, 2025 <br><br> 2:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://web.math.unifi.it/users/brugnano/LuigiBrugnano_2.jpg"></td>
<td><a href="https://web.math.unifi.it/users/brugnano/">Luigi Brugnano</a><br> University of Florence, Italy</td>
<td><strong>Recent Advances in the Numerical Solution of Differential Equations</strong> <br><br> The numerical solution of ODE-IVPs has been the subject of many investigations since many decades, and a number of reliable, state-of-art codes are available for their solution. However, when stability results by first approximation does not apply, things become more involved, and general purpose codes may fail. This is the case, e.g., of Hamiltonian problems, for which the class of Runge-Kutta methods, known as Hamiltonian Boundary Value Methods (HBVMs), has been recently proposed. Such methods, in turn, are equivalent to a truncated expansion of the vector field along the Legendre orthonormal polynomial basis. This fact, coupled with the availability of a very efficient nonlinear iteration for their implementation, allows the use of HBVMs as spectrally accurate methods in time. The truncated expansion can be also regarded as imposing the orthogonality of the residual, w.r.t. a suitable inner product, to all polynomials of a certain degree. This allows, in turn, the use of different polynomial bases, as well as the extension of the approach for coping with different differential problems. As an example, the extension to the case of fractional differential equations has been recently studied.</td>
<td>February 17, 2025 <br><br> 5:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src=""></td>
<td><a href="https://www.dm.uniba.it/it/members/iavernaro/felice-iavernaro">Felice Iavernaro</a><br> University of Bari Aldo Moro, Italy</td>
<td><strong>The principle of maximum entropy in least squares approximation</strong> <br><br> We consider using a maximal entropy argument to determine the coefficients of the approximating function and squared error weights simultaneously as output of a (weighted) least-squares approximation problem. Interpreting the weights as a probability distribution, we choose them by maximizing the “amount of uncertainty” or entropy, subject to the constraint that the mean squared error is prescribed to a desired (small) value. By acting on this error, we get a robust method for linear and nonlinear regression that automatically detects and removes outliers from the dataset during the fitting procedure, by assigning them a very small weight. We consider the use of both polynomials and univariate/bivariate splines. To show the potential of the maximal-entropy approach in least squares approximation of data we consider a number of illustrations in different application fields.</td>
<td>February 17, 2025 <br><br> 4:15 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSw93tDSDeTsCm44fZ8X11tNCh5sMoSB_bcVA&s"></td>
<td><a href="https://unidistance.ch/en/profile/matthias-voigt">Matthias Voigt</a><br> UniDistance, Switzerland</td>
<td><strong>Treating inhomogeneous initial conditions in balancing-based model reduction</strong> <br><br> In standard balanced truncation model order reduction, the initial condition is typically ignored in the reduction procedure and is assumed to be zero instead. However, such a reduced-order model may be a bad approximation to the full-order system, if the initial condition is not zero. In the literature there are several attempts for modified reduction methods at the price of having no error bound or only a posteriori error bounds which are often too expensive to evaluate. In this talk we propose a new balancing procedure that is based on a shift transformation on the state. We first derive a joint projection reduced-order model in which the part of the system depending only on the input and the one depending only on the initial value are reduced at once and we prove an a priori error bound. With this result at hand, we derive a separate projection procedure in which the two parts are reduced separately. This gives the freedom to choose different reduction orders for the different subsystems. Moreover, we discuss how the reduced-order models can be constructed in practice. Since the error bounds are parameter-dependent, we show how they can be optimized efficiently. We conclude by comparing our results with the ones from the literature by a series of numerical experiments. This is joint work with Christian Schröder.</td>
<td>February 13, 2025 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Room D, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.redleonardo.es/wp-content/uploads/sites/6/2022/10/Mari%CC%81a-Lo%CC%81pez-Ferna%CC%81ndez-456x570-.jpg"></td>
<td><a href="https://www.uma.es/edanya/info/131834/maria-lopez-fernandez/">María López Fernández</a><br> University of Malaga, Spain</td>
<td><strong>Generalized Convolution Quadrature for non smooth sectorial problems</strong> <br><br> We consider the application of the generalized Convolution Quadrature (gCQ) to approximate the solution of an important class of sectorial problems. The gCQ is a generalization of Lubich's Convolution Quadrature (CQ) that allows for variable steps. The available stability and convergence theory for the gCQ requires non realistic regularity assumptions on the data, which do not hold in many applications of interest, such as the approximation of subdiffusion equations. It is well known that for non smooth enough data the original CQ, with uniform steps, presents an order reduction close to the singularity. We generalize the analysis of the gCQ to data satisfying realistic regularity assumptions and provide sufficient conditions for stability and convergence on arbitrary sequences of time points. We consider the particular case of graded meshes and show how to choose them optimally, according to the behaviour of the data. An important advantage of the gCQ method is that it allows for a fast and memory reduced implementation. We describe how the fast and oblivious gCQ can be implemented and illustrate our theoretical results with several numerical experiments. <br><br> <a href="https://drive.google.com/file/d/1FH5seMIlSFSbMlOsJ_21z54eKqDz3IOi/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>January 29, 2025 <br><br> 5:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://relx-elsevier-erms--c.documentforce.com/servlet/servlet.ImageServer?id=015Tl00000GF51PIAT&oid=00D1t000000qIy5EAE&lastMod=1735545688869"></td>
<td><a href="https://gauss.uc3m.es/fdopico/fdopico.html">Froilán Martínez Dopico</a><br> Universidad Carlos III de Madrid, Spain</td>
<td><strong>Polynomial and rational matrices with prescribed data</strong> <br><br> We study necessary and sufficient conditions for the existence of polynomial and rational matrices with different prescribed data. First, we consider the problem for polynomial matrices when the size, degree, rank, invariant factors, infinite elementary divisors, and the minimal indices of their left and right null spaces are prescribed and prove that a polynomial matrix with these data exists if and only if these data satisfy a surprisingly simple unique condition related to a fundamental constraint known as the "index sum theorem'". In the second place, we extend this result to rational matrices when the size, rank, invariant rational functions, invariant orders at infinity, and minimal indices of their left and right null spaces are prescribed. The data prescribed so far are called in the literature the "complete structural data" or the "complete eigenstructure" of the polynomial or rational matrix. Finally, in addition to the complete eigenstructure, we also prescribe the minimal indices of the row and column spaces and show that the simple condition found in the previous problems must be completed with a majorization relation among the involved indices, the degrees of the invariant factors and of the infinite elementary divisors.</td>
<td>January 23, 2024 <br><br> 2:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://mysite.ku.edu.tr/emengi/wp-content/uploads/sites/323/2024/02/emengi.jpg"></td>
<td><a href="http://home.ku.edu.tr/~emengi/">Emre Mengi</a><br> Koc University, Turkey</td>
<td><strong>A Subspace Framework for Large-Scale H-infinity Norm Computation</strong> <br><br> I will describe a subspace framework to compute the H-infinity norm of the transfer function of a control system with large order, a commonly employed objective to minimize for instance in controller design, model order reduction and robust control. Our setting encompasses the transfer functions of descriptor systems, delay systems and many other non-rational transfer functions. In this H-infinity context, we employ tools from model order reduction such as Petrov-Galerkin projections in the state space. The talk is intended to be self-contained as much as possible.</td>
<td>December 17, 2024 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://mysite.ku.edu.tr/emengi/wp-content/uploads/sites/323/2024/02/emengi.jpg"></td>
<td><a href="http://home.ku.edu.tr/~emengi/">Emre Mengi</a><br> Koc University, Turkey</td>
<td><strong>Large-Scale Eigenvalue Optimization</strong> <br><br> The talk concerns a subspace framework for the general setting of optimizing a prescribed eigenvalue of a large parameter-dependent matrix. The approach aims to replace the large parameter-dependent matrix with a smaller one obtained via orthogonal projections. We analyze the convergence properties of the framework, and point out open problems. An adaptation of the framework for large-scale semidefinite programs is presented.</td>
<td>December 11, 2024 <br><br> 4:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://upload.wikimedia.org/wikipedia/commons/1/13/VYuProtasovCorrMembRASProfRAS.jpg"></td>
<td><a href="https://www.ing.univaq.it/personale/scheda_personale.php?codice=536">Vladimir Protasov</a><br> University of L'Aquila, Italy</td>
<td><strong>The Newton aerodynamic problem: all over again after 300 years</strong> <br><br> In 1687 Isaac Newton in his main work "Principia'' posed the following Aerodynamic Problem: find the convex surface of the minimal frontal resistance during its uniform motion through an inviscid and incompressible medium. The surface must contain a given disc orthogonal to the vector of velocity and have a given altitude. The solution of Newton became a classical example in the calculus of variations. However, in early 1990s G.Butazzo, D.Kawohl, and P.Guasoni presented a surface of a smaller resistance. They showed that the optimality of Newtons's surface concerns only a special case (although, considered to be general by most of specialists). The aerodynamic problem had to be solved again under general assumptions, which turned out to be a hard task. The solution is still unknown, although some properties of the optimal surface have been established. We give a survey of some of the known results including construction of non-convex surfaces of arbitrary small resistance and of invisible surfaces. Then we present a new approach to analyze the optimal convex surface by using inequalities between derivatives. Some of these inequalities are, probably, of independent interest. This is a joint work with A.Plakhov (University of Aveiro, Portugal).</td>
<td>November 25, 2024 <br><br> 4:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.jesus.cam.ac.uk/sites/default/files/styles/person/public/profile/carola-bibiane_schonlieb.jpg?h=2915a71b&itok=bSbDqF7R"></td>
<td><a href="https://www.damtp.cam.ac.uk/person/cbs31">Carola-Bibiane Schönlieb</a> <br> University of Cambridge, United Kingdom</td>
<td><strong>Mathematical imaging: from PDEs to deep learning for images</strong> <br><br> Images are a rich source of beautiful mathematical formalism and analysis. Associated mathematical problems arise in functional and non-smooth analysis, the theory and numerical analysis of nonlinear partial differential equations, inverse problems, harmonic, stochastic and statistical analysis, and optimisation, just to name a few. Applications of mathematical imaging are profound and arise in biomedicine, material sciences, astronomy, digital humanities, as well as many technological developments such as autonomous driving, facial screening and many more. In this talk I will discuss my perspective onto mathematical imaging, share my fascination and vision for the subject. I will then zoom into one research problem that I am currently most excited about and that we helped make first advances on: the mathematical formalisation of machine learned approaches for solving inverse imaging problems.</td>
<td>November 21, 2024 <br><br> 3:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://cs.duke.edu/sites/cs.duke.edu/files/styles/square_small/public/externals/53effb42525be98301e495b63021eaee.jpg?itok=NHhAEUHw"></td>
<td><a href="https://ece.auth.gr/en/staff/nikolaos-pitsianis/">Nikos Pitsianis</a> <br> Aristotle University of Thessaloniki, Greece</td>
<td><strong>The Fiedler Connection to Graph Clustering with Resolution Variation</strong> <br><br> TBA</td>
<td>November 20, 2024 <br><br> 5:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
</tbody>
</table>
<h3 id="academic-year-202324">Academic Year 2023/24</h3>
<table>
<thead>
<tr>
<th>Speaker</th>
<th></th>
<th>Title, Abstract &amp; Other Info</th>
<th>Date &amp; Venue</th>
</tr>
</thead>
<tbody>
<tr>
<td><img style="width:60px;" src="https://health.uct.ac.za/sites/default/files/styles/square_med/public/contacts/paolo_bio.png?h=97c04a2e&itok=MTHP_1z_"></td>
<td><a href="https://health.uct.ac.za/pharmacometrics/contacts/paolo-denti">Paolo Denti</a> <br> University of Cape Town, South Africa</td>
<td><strong>Pharmacometrics: a quantitative tool for pharmacological research</strong> <br><br></td>
<td>July 1, 2024 <br><br> 11:00 AM <br><br> <a href="https://num-gssi.github.io/venues/">Library, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/131afc1cb16b90a10de84b1d079bb47e_L.jpg"></td>
<td><a href="https://na.uni-tuebingen.de/~lubich/">Christian Lubich</a><br> University of Tübingen, Germany</td>
<td><strong>Regularized dynamical parametric approximation</strong><br><br>This talk is about the numerical approximation of evolution equations by nonlinear parametrizations $u(t)=\Phi(q(t))$ with time-dependent parameters $q(t)$, which are to be determined in the computation. The motivation comes from approximations in quantum dynamics by multiple Gaussians and approximations of various dynamical problems by tensor networks and neural networks. In all these cases, the parametrization is typically irregular: the derivative $\Phi'(q)$ can have arbitrarily small singular values and may have varying rank. We derive approximation results for a regularized approach in the time-continuous case as well as in time-discretized cases. With a suitable choice of the regularization parameter and the time stepsize, the approach can be successfully applied in irregular situations, even though it runs counter to the basic principle in numerical analysis to avoid solving ill-posed subproblems when aiming for a stable algorithm. Numerical experiments with sums of Gaussians for approximating quantum dynamics and with neural networks for approximating the flow map of a system of ordinary differential equations illustrate and complement the theoretical results. The talk is based on joint work with Caroline Lasser, Jörg Nick and Michael Feischl.</td>
<td>June 6, 2024 <br><br> 3:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=uzhMRhEAAAAJ&citpid=1"></td>
<td><a href="http://www.paolofreguglia.it/">Paolo Freguglia</a> <br> University of L'Aquila, Italy</td>
<td><strong>On the corporate organization. A proposal</strong> <br><br> Inspired by the classic conceptions of “economic equilibrium” related to the Arrow (1971) and Debreu (1959) model, we have constructed a mathematical paradigm. We start from a possible “economic game” which simulates the relationship between companies and customers, involving company sales, costs and value-assets. So we establish an equilibrium which can be seen as a weighted average of a random variable. Then we arrive at a basic iterable algebraic equation that establishes a relationship between sales and its estimated forecast. The analysis of the evolution of the simple deviations between sales and estimate forecasts is also proposed. Afterwards we keep into account the actual results related to a manufacturing company (with 130 clerks and workers), limiting our analysis to the evolution during 40 months (time unit is the month) of a single product relating to a single customer. In conclusion we gave some ideas about the notion of “sales trend”.</td>
<td>May 28, 2024 <br><br> 5:15 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://numpi.dm.unipi.it/wp-content/uploads/2022/12/SL_Portrait_SmallSize.jpg"></td>
<td><a href="https://sites.google.com/view/santololeveque/home">Santolo Leveque</a><br> Scuola Normale Superiore of Pisa, Italy</td>
<td><strong>Parallel-in-Time Solver for the All-at-Once Runge-Kutta Discretization</strong> <br><br> Time-dependent PDEs arise quite often in many scientific areas, such as mechanics, biology, economics, or chemistry, just to name a few. Of late, researchers have devoted their effort in devising parallel-in-time methods for the numerical solution of time-dependent PDEs, adding a new dimension of parallelism and allowing to speed-up the solution process on modern supercomputers. In this talk, we present a parallel-in-time preconditioner for the all-at-once linear system arising when employing a Runge--Kutta method in time. The resulting system is solved iteratively for the numerical solution and for the stages of the method. The proposed preconditioner results in a block-diagonal solution for the stages, and a Schur complement obtained by solving again systems for the stages. A range of numerical experiments validate the robustness of the preconditioner with respect to the discretization parameters and to the number of stages, showing the speed-up achieved on a parallel architecture. This is a joint work with Luca Bergamaschi (University of Padua), Angeles Martinez (University of Trieste), and John W. Pearson (University of Edinburgh).</td>
<td>May 28, 2024 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.maths.ed.ac.uk/~dhigham/dhigham_web_pic.jpg"></td>
<td><a href="https://www.maths.ed.ac.uk/~dhigham/">Desmond Higham</a><br> University of Edinburgh, United Kingdom</td>
<td><strong>A Numerical Analysis Perspective on the Stability of AI Systems</strong> <br><br> Over the last decade, adversarial attack algorithms have revealed instabilities in deep learning tools. These algorithms raise issues regarding safety, reliability and interpretability in artificial intelligence (AI); especially in high risk settings. Ideas from numerical analysis play key roles in this landscape. From a practical perspective, there has been a war of escalation between those developing attack and defence strategies. At a more theoretical level, researchers have also studied bigger picture questions concerning the existence and computability of successful attacks. I will present examples of attack algorithms in image classification and optical character recognition. I will also outline recent results on the overarching question of whether, under reasonable assumptions, it is inevitable that AI tools will be vulnerable to attack.</td>
<td>May 8, 2024 <br><br> 5:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gla.ac.uk/media/Media_569241_smxx.jpg"></td>
<td><a href="https://www.gla.ac.uk/schools/computing/staff/catherinehigham/">Catherine Higham</a><br> University of Glasgow, United Kingdom</td>
<td><strong>Quantum imaging with deep learning algorithms</strong> <br><br> Quantum imaging technology offers time-efficient, lightweight, less-invasive and low-cost solutions in many different contexts including autonomous driving, security and health. Enhancing this technology with deep learning addresses challenges arising in experimental optimisation, inverse and classification/regression tasks and improves overall performance. I will talk about the deep learning algorithms I have developed for several projects. These include real time scene and depth reconstruction for single photon sensor camera and LiDAR systems, and high-speed imaging using a Micro LED-on-CMOS light projector.</td>
<td>May 8, 2024 <br><br> 4:15 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://mysite.ku.edu.tr/emengi/wp-content/uploads/sites/323/2024/02/emengi.jpg"></td>
<td><a href="http://home.ku.edu.tr/~emengi/">Emre Mengi</a><br> Koc University, Turkey</td>
<td><strong>Large-scale minimization of the pseudospectral abscissa</strong><br><br>The minimization of the spectral abscissa of a matrix dependent on parameters has drawn interest in the last couple of decades. The problem is motivated especially by the stability considerations for the associated linear control system. The major difficulty in the minimization of the spectral abscissa is that its dependence on the parameters is non-Lipschitz. A remedy to this is, for a prescribed epsilon &gt; 0, minimizing the epsilon-pseudospectral abscissa, the real part of the rightmost point in the set consisting of eigenvalues of all matrices at a distance of epsilon with respect to the spectral norm. We present a subspace framework to minimize the epsilon-pseudospectral abscissa of a large matrix dependent on parameters analytically. At every subspace iteration, a one-sided subspace restriction on the parameter-dependent matrix yields a small rectangular pseudospectral abscissa minimization problem. We expand the restriction subspace based on the minimizer of this small problem. We prove in theory for the proposed subspace framework that, assuming the global minimizers of the small problems are retrieved, convergence to the global minimizer of the original large-scale pseudospectral abscissa minimization problem occurs in the infinite dimensional setting. Our theoretical findings are illustrated on real large-scale examples that concern the stabilization by static output feedback of benchmark linear control systems.</td>
<td>April 23, 2024 <br><br> 4:45 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.ymmor2024.uni-stuttgart.de/img/20fd108d02064d0f5038edd5441b5f86_XL.jpg?__scale=w:220,h:220,cx:0,cy:101,cw:900,ch:900"></td>
<td><a href="https://www.simtech.uni-stuttgart.de/exc/people/Manucci-00003/">Mattia Manucci</a><br> University of Stuttgart, Germany</td>
<td><strong>Approximating the smallest eigenvalue of large Hermitian matrices that depend on parameters</strong> <br><br></td>
<td>April 23, 2024 <br><br> 3:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.unige.ch/~hairer/pictures/hai07-2.jpg"></td>
<td><a href="https://www.unige.ch/~hairer/">Ernst Hairer</a><br> Université de Genève, Switzerland</td>
<td><strong>Leapfrog methods for relativistic charged-particle dynamics</strong> <br><br> A basic leapfrog integrator and its variational variant are proposed and studied for the numerical integration of the equations of motion of relativistic charged particles in an electromagnetic field. The methods are based on a four-dimensional formulation of the equations of motion. Structure-preserving properties of the numerical methods are analysed, in particular conservation and long-time near-conservation of energy and mass shell as well as preservation of volume in phase space. In the non-relativistic limit, the considered methods reduce to the Boris algorithm for non-relativistic charged-particle dynamics and its variational variant. This talk is based on joint-work with Christian Lubich</td>
<td>April 18, 2024 <br><br> 2:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSw93tDSDeTsCm44fZ8X11tNCh5sMoSB_bcVA&s"></td>
<td><a href="https://unidistance.ch/en/profile/matthias-voigt">Matthias Voigt</a> <br> FernUni, Switzerland</td>
<td><strong>Structure-Preserving Model Order Reduction of Dynamical Systems</strong> <br><br> Model order reduction is a field of mathematics that deals with the complexity reduction of mathematical models in order to reduce the computational costs of tasks such as numerical simulation, optimization, or control. In this talk, first an overview of the field will be given and two of the classical systems theoretic reduction methods (balanced truncation and IRKA) will be reviewed. The second part of the presentation will focus on structure-preserving reduction methods for structured models. This includes a variant of balanced truncation for symmetric second-order systems and a rational fitting method for the class of port-Hamiltonian systems.</td>
<td>January 17, 2024 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://media.licdn.com/dms/image/D4D03AQGaVhKuFlFKcQ/profile-displayphoto-shrink_200_200/0/1681729173189?e=2147483647&v=beta&t=UsEWD1AH3l-A8Bivoyyaxy4LxxaH5XIxTDSBzy-xk-I"></td>
<td><a href="https://it.linkedin.com/in/alessandro-valerio-026081206">Alessandro Valerio</a><br> University of Trondheim, Norway</td>
<td><strong>Neuroscience - AI</strong> <br><br> In this seminar, Alessandro Valerio, a graduate in neuroscience, explores the field of neuroscience and its potential intersections with artificial intelligence. Alessandro has an educational background in biology and neuroscience from the University of L’Aquila and Trieste, complemented by research experiences at SISSA in Trieste and at the Kavli Institute for System Neuroscience in Trondheim. The seminar provides an overview of the brain's structure, covering aspects from the macroscopic to the molecular level. A significant focus is given to the role of electrophysiological methods in neuroscience. Alessandro details both in vitro and in vivo techniques, which are crucial in understanding the intricacies of neural dynamics. A part of the seminar is dedicated to Alessandro's research journey. His work at SISSA centered on cellular neurobiology and in vitro electrophysiology, particularly in studying rhythmogenesis mechanisms. His journey continued in Trondheim, where he engaged in in vivo electrophysiology and multisensory integration studies at the Kavli Institute for System Neuroscience. The seminar concludes with Alessandro presenting his research goals. He aims to leverage AI advancements in neuroscience research and reciprocally apply neuroscience insights to advance AI development. This includes a focus on utilizing deep learning for EEG signal classification and exploring the potential of bio-inspired neural networks.</td>
<td>January 10, 2024 <br><br> 6:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://math.aalto.fi/pics/people/ap-2023/file_crop1_1208991_y_384.jpg"></td>
<td><a href="https://math.aalto.fi/en/people/lauri.nyman">Lauri Nyman</a><br> Aalto University, Finland</td>
<td><strong>Nearest singular pencil via Riemannian optimization</strong> <br><br> The problem of finding the nearest singular pencil to a given regular, complex or real, n × n matrix pencil A + λB is a long-standing problem in Numerical Linear Algebra. This problem turned out to be very difficult and, so far, just a few numerical algorithms are available in the literature for its solution, though they may be very expensive from a computational point of view. In this talk, we introduce a new algorithm for solving this problem based on Riemannian optimization, which looks for the closest singular pencil via the minimization of an objective function over the cartesian product of the unitary group by itself. Moreover, we present a collection of numerical experiments that show that the new algorithm can deal effectively with pencils of larger sizes than those considered by previous algorithms and find minimizers of, at least, the same quality than previous algorithms.</td>
<td>January 10, 2024 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.ymmor2024.uni-stuttgart.de/img/20fd108d02064d0f5038edd5441b5f86_XL.jpg?__scale=w:220,h:220,cx:0,cy:101,cw:900,ch:900"></td>
<td><a href="https://www.simtech.uni-stuttgart.de/exc/people/Manucci-00003/">Mattia Manucci</a><br> University of Stuttgart, Germany</td>
<td><strong>Model Order Reduction for switched Differential Algebraic Equations</strong> <br><br> In this presentation, we will discuss a projection-based Model Order Reduction (MOR) for large-scale systems of switched Differential Algebraic Equations (sDAEs). The main idea relies on exploiting the Quasi-Weierstrass form of each mode of the sDAEs system. Then, we can show that, under certain reasonable assumptions, the output of the sDAEs system is equivalent to the output of a switched system of ordinary differential equations (ODEs) with state jumps between the modes. We present how to construct a reduced system by computing the controllability and observability Gramians associated with the solution of generalized Lyapunov equations for bilinear systems. Finally, we discuss how to efficiently compute an approximation of the solution of such generalized Lyapunov equations, with error control, when the associated matrices are sparse and large. Numerical results are presented to showcase the efficiency and effectiveness of the developed MOR method.</td>
<td>December 20, 2023 <br><br> 5:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Conference Room, ex-INPS building</a></td>
</tr>
</tbody>
</table>
<h3 id="academic-year-202223">Academic Year 2022/23</h3>
<table>
<thead>
<tr>
<th>Speaker</th>
<th></th>
<th>Title, Abstract &amp; Other Info</th>
<th>Date &amp; Venue</th>
</tr>
</thead>
<tbody>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/131afc1cb16b90a10de84b1d079bb47e_L.jpg"></td>
<td><a href="https://na.uni-tuebingen.de/~lubich/">Christian Lubich</a><br> Universität Tübingen, Germany</td>
<td><strong>Time integration of tree tensor networks</strong> <br><br> First I report on recent numerical experiments with time-dependent tree tensor network algorithms for the approximation of quantum spin systems. I will then describe the basics in the design of time integration methods that are robust to the usual presence of small singular values, that have good structure-preserving properties (norm, energy conservation or dissipation), and that allow for rank (= bond dimension) adaptivity and also have some parallelism. This discussion of basic concepts will be done for the smallest possible type of tensor network differential equations, namely low-rank matrix differential equations. Once this simplest case is understood, there is a systematic path to the extension of the integrators and their favourable properties to general tree tensor networks.</td>
<td>June 8, 2023 <br><br> 3:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.concordia.ca/etc/designs/concordia/resources/file.8744.512.jpg"></td>
<td><a href="https://sites.google.com/view/paglia">Simone Brugiapaglia</a> <br> Concordia University, Canada</td>
<td><strong>The mathematical foundations of deep learning: from rating impossibility to practical existence theorems</strong> <br><br> Deep learning is having a profound impact on industry and scientific research. Yet, while this paradigm continues to show impressive performance in a wide variety of applications, its mathematical foundations are far from being well established. In this talk, I will present recent developments in this area by illustrating two case studies. <br> First, motivated by applications in cognitive science, I will present 'rating impossibility' theorems. They identify frameworks where deep learning is provably unable to generalize outside the training set for the seemingly simple task of learning identity effects, i.e. classifying whether pairs of objects are identical or not. <br> Second, motivated by applications in scientific computing, I will illustrate 'practical existence' theorems. They combine universal approximation results for deep neural networks with compressed sensing and high-dimensional polynomial approximation theory. As a result, they yield sufficient conditions on the network architecture, the training strategy, and the number of samples able to guarantee accurate approximation of smooth functions of many variables. <br> Time permitting, I will also discuss work in progress and open questions.</td>
<td>June 1, 2023 <br><br> 2:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.unige.ch/~hairer/pictures/hai07-2.jpg"></td>
<td><a href="https://www.unige.ch/~hairer/">Ernst Hairer</a><br> Université de Genève, Switzerland</td>
<td><strong>Large-stepsize integrators for charged particles in a strong magnetic field</strong> <br><br> This talk considers the numerical treatment of the differential equation that describes the motion of electric particles in a strong magnetic field. A standard integrator is the Boris algorithm which, for small stepsizes, can be analysed by classical techniques. For a strong magnetic field the solution is highly oscillatory and the numerical integration is more challenging. New modifications of the Boris algorithm are discussed, and their accuracy and long-time behaviour are studied with means of modulated Fourier expansions. Emphasis is put on the situation where the stepsize is proportional to (or larger than) the wavelength of the oscillations. <br> The presented results have been obtained in collaboration with Christian Lubich.</td>
<td>April 20, 2023 <br><br> 2:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.raiplaysound.it/cropgd/184x184/dl/img/2020/06/11/1591826711142_Picc.jpg"></td>
<td><a href="https://research.uniroma1.it/researcher/dc3e4ad0d30e7f0523a5916ac9d4b0bbfee098c92a492c5f8cbe9f55">Mauro Piccioni</a><br> Sapienza Università di Roma, Italy</td>
<td><strong>Estimating the interaction graph for a class of Galves-Locherbach models (Part 2)</strong> <br><br> We explain how to estimate the presence and the nature of the interactions (either excitatory or inhibitory) in a multivariate point process modeling a network of spiking neurons (Galves and Locherbach, JSP 2013). In the first talk a Markovian model is analyzed whereas in the second delayed inhibitory interactions have to be detected.</td>
<td>April 19, 2023 <br><br> 5:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://i1.rgstatic.net/ii/profile.image/277615211499538-1443200032842_Q512/Emilio-De-Santis.jpg"></td>
<td><a href="https://research.uniroma1.it/researcher/ee5bce0832867509165023ba3b935d190e57706edfdaad4976624d55">Emilio De Santis</a><br> Sapienza Università di Roma, Italy</td>
<td><strong>Estimating the interaction graph for a class of Galves-Locherbach models (Part 1)</strong> <br><br> We explain how to estimate the presence and the nature of the interactions (either excitatory or inhibitory) in a multivariate point process modeling a network of spiking neurons (Galves and Locherbach, JSP 2013). In the first talk a Markovian model is analyzed whereas in the second delayed inhibitory interactions have to be detected.</td>
<td>April 19, 2023 <br><br> 5:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.tu-chemnitz.de/mathematik/wire/pics/Bergermann_SD.jpg"></td>
<td><a href="https://www.tu-chemnitz.de/mathematik/wire/people/bergermann.php">Kai Bergermann</a><br> TU Chemnitz, Germany</td>
<td><strong>Adaptive rational Krylov methods for exponential Runge--Kutta integrators</strong> <br><br> We consider the solution of large stiff systems of ordinary differential equations with explicit exponential Runge--Kutta integrators. These problems arise from semi-discretized semi-linear parabolic partial differential equations on continuous domains or on inherently discrete graph domains. A series of results reduces the requirement of computing linear combinations of $\varphi$-functions in exponential integrators to the approximation of the action of a smaller number of matrix exponentials on certain vectors. State-of-the-art computational methods use polynomial Krylov subspaces of adaptive size for this task. They have the drawback that the required Krylov subspace iteration numbers to obtain a desired tolerance increase drastically with the spectral radius of the discrete linear differential operator, e.g., the problem size. We present an approach that leverages rational Krylov subspace methods promising superior approximation qualities. We prove a novel a-posteriori error estimate of rational Krylov approximations to the action of the matrix exponential on vectors for single time points, which allows for an adaptive approach similar to existing polynomial Krylov techniques. We discuss pole selection and the efficient solution of the arising sequences of shifted linear systems by direct and preconditioned iterative solvers. Numerical experiments show that our method outperforms the state of the art for sufficiently large spectral radii of the discrete linear differential operators. The key to this are approximately constant rational Krylov iteration numbers, which enable a near-linear scaling of the runtime with respect to the problem size.</td>
<td>April 18, 2023 <br><br> 5:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://media.licdn.com/dms/image/v2/C5603AQFB4eG-GGbUoQ/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1517245847571?e=2147483647&v=beta&t=K9wFEmSKnTJY-4lXfQJBV32iCBPWLilLU6KkKFAXhro"></td>
<td><a href="https://na.uni-tuebingen.de/~ceruti/">Gianluca Ceruti</a><br> EPFL, Switzerland</td>
<td><strong>A rank-adaptive robust BUG for dynamical low-rank approximation</strong> <br><br> In the present contribution, a rank-adaptive integrator for the dynamical low-rank approximation of matrix differential equations is introduced. First, the dynamical low-rank approximation together with the projector-splitting numerical integrator is summarised. Then, recent developments on the field are presented. The so-called fixed-rank unconventional BUG integrator is introduced and analysed. Next, a simple but extremely effective modification allowing for an adaptive choice of the rank, using subspaces generated by the integrator itself, is illustrated. It is shown that the novel BUG adaptive low-rank integrator retains the exactness, robustness and symmetry-preserving properties of the previously proposed fixed-rank integrators. Beyond that, up to the truncation tolerance, the rank-adaptive integrator preserves the norm when the differential equation does, it preserves the energy for Schroedinger equations and Hamiltonian systems, and it preserves the monotonic decrease in gradient flows. This seminar will focus on the numerical error analysis of the adaptive low-rank integrator. Furthemore, the first theoretically solid application to low-rank training in machine learning will be discussed.  <br> The present contribution is based upon joint works with Ch. Lubich, J. Kusch, and F. Tudisco. The last developments in the field of machine learning have been possible only due to the great contributions of PhD candidates E. Zangrando (GSSI) and S. Schotthoefer (KIT).</td>
<td>March 16, 2023 <br><br> 3:00 PM <br><br> Zoom meeting</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.lincei.it/sites/default/files/2631.jpg"></td>
<td><a href="https://mox.polimi.it/people/alfio-quarteroni/">Alfio Quarteroni</a><br> Politecnico di Milano, Italy, and EPFL, Switzerland</td>
<td><strong>A Mathematical Heart</strong> <br><br> In this presentation I will report on the most recent achievements of the iHEART project, aimed at developing a comprehensive accurate mathematical and numerical model for the simulation of the complete cardiac function.</td>
<td>December 15, 2022 <br><br> 3:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
</tbody>
</table>
<h3 id="academic-year-202122">Academic Year 2021/22</h3>
<table>
<thead>
<tr>
<th>Speaker</th>
<th></th>
<th>Title, Abstract &amp; Other Info</th>
<th>Date &amp; Venue</th>
</tr>
</thead>
<tbody>
<tr>
<td><img style="width:60px;" src="https://mysite.ku.edu.tr/emengi/wp-content/uploads/sites/323/2024/02/emengi.jpg"></td>
<td><a href="http://home.ku.edu.tr/~emengi/">Emre Mengi</a><br> Koc University, Turkey</td>
<td><strong>Large-Scale Estimation of the Dominant Poles of a Transfer Function</strong> <br><br> The dominant poles of the transfer function of a descriptor system provide important insight into the behavior of the system. They indicate the parts of the imaginary axis where the transfer function exhibits large norm. Moreover,  the dominant poles and corresponding eigenvectors can be put in use to form a reduced-order approximation to the system. In the talk, I will describe a subspace framework to compute a prescribed number of dominant poles of a large-scale descriptor system. The framework applies Petrov-Galerkin projections to the original system, then computes the dominant poles of the projected small-scale system, for instance by the QZ algorithm, and expands the subspaces so that the projected system after the subspace expansion interpolates the original system at these dominant poles. I will explain why the subspace framework converges at a quadratic rate, and report numerical results illustrating the rapid convergence, and accuracy of the approach.</td>
<td>September 19, 2022 <br><br> 1:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://i0.wp.com/numpi.dm.unipi.it/wp-content/uploads/2022/09/massei1-e1662728627306.jpg?fit=696%2C696&ssl=1"></td>
<td><a href="https://sites.google.com/view/stefanomassei/home">Stefano Massei</a> <br> University of Pisa, Italy</td>
<td><strong>Improved parallel-in-time integration via low-rank updates and interpolation</strong> <br><br> This work is concerned with linear matrix equations that arise from the space-time discretization of time-dependent linear partial differential equations (PDEs). Such matrix equations have been considered, for example, in the context of parallel-in-time integration leading to a class of algorithms called ParaDiag. We develop and analyze two novel approaches for the numerical solution of such equations. Our first approach is based on the observation that the modification of these equations performed by ParaDiag in order to solve them in parallel has low rank. Building upon previous work on low-rank updates of matrix equations, this allows us to make use of tensorized Krylov subspace methods to account for the modification. Our second approach is based on interpolating the solution of the matrix equation from the solutions of several modifications. Both approaches avoid the use of iterative refinement needed by ParaDiag and related space-time approaches in order to attain good accuracy. In turn, our new approaches have the potential to outperform, sometimes significantly, existing approaches. This potential is demonstrated for several different types of PDEs.</td>
<td>September 14, 2022 <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://s3.amazonaws.com/peerj_prod_upload/images/profile/m%2Fa%2FJvAsovVEZvJtestBE039Lg%3D%3D%2Fi200_6482c7fd9897b7.04158971.jpeg"></td>
<td><a href="https://eps.leeds.ac.uk/computing/staff/14034/massimiliano-fasi">Massimiliano Fasi</a> <br> Durham University, UK</td>
<td><strong>CPFloat: A C Library for Emulating Low-Precision Arithmetic</strong> <br><br> Low-precision floating-point arithmetic can be simulated via software by executing each arithmetic operation in hardware and rounding the result to the desired number of significant bits. For IEEE-compliant formats, rounding requires only standard mathematical library functions, but handling subnormals, underflow, and overflow demands special attention, and numerical errors can cause mathematically correct formulae to behave incorrectly in finite arithmetic. Moreover, the ensuing algorithms are not necessarily efficient, as the library functions these techniques build upon are typically designed to handle a broad range of cases and may not be optimized for the specific needs of floating-point rounding algorithms. CPFloat is a C library that offers efficient routines for rounding arrays of binary32 and binary64 numbers to lower precision. The software exploits the bit level representation of the underlying formats and performs only low-level bit manipulation and integer arithmetic, without relying on costly library calls. In numerical experiments the new techniques bring a considerable speedup (typically one order of magnitude or more) over existing alternatives in C, C++, and MATLAB. To the best of our knowledge, CPFloat is currently the most efficient and complete library for experimenting with custom low-precision floating-point arithmetic available in any language.</td>
<td>June 24, 2022 <br><br> 1:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Library, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://lh6.googleusercontent.com/proxy/GrP5muGpg_k4epag-dpMBKMuOJhAidXv0blofLl4Ez0BCeWR3LWjkwxobLnyTorjETrVAZ_siBMVKkkTIGvm8dVxuIibFjhmFvYfccUqp3HdD-U"></td>
<td><a href="http://scienze-como.uninsubria.it/serra/">Stefano Serra-Capizzano</a> <br> University of Insubria, Italy</td>
<td><strong>The GLT class as a Generalized Fourier Analysis and applications</strong> <br><br> Recently, the class of Generalized Locally Toeplitz (GLT) sequences has been introduced [1, 2] as a generalization both of classical Toeplitz sequences and of variable coefficient differential operators and, for every sequence of the class, it has been demonstrated that it is possible to give a rigorous description of the asymptotic spectrum in terms of a function (the symbol) that can be easily identified. <br> This generalizes the notion of a symbol for differential operators also of fractional type (discrete and continuous) or for Toeplitz sequences for which it is identified through the Fourier coefficients and is related to the classical Fourier Analysis. <br> The GLT class has nice algebraic properties and indeed it has been proven that it is stable under linear combinations, products, and inversion when the sequence which is inverted shows a sparsely vanishing symbol (sparsely vanishing symbol = a symbol which vanishes at most in a set of zero Lebesgue measure). Furthermore, the GLT class virtually includes any approximation by local methods (Finite Difference, Finite Element, Isogeometric Analysis of partial differential equations (PDEs)) and, based on this, we demonstrate that our results on GLT sequences can be used in a PDE setting in various directions. <br><br> [1] S. Serra-Capizzano. <em>Generalized Locally Toeplitz sequences: spectral analysis and applications to discretized partial differential equations</em>. Linear Algebra Appl. 366 (2003), 371–402. <br> [2] S. Serra-Capizzano. <em>The GLT class as a generalized Fourier Analysis and applications</em>. Linear Algebra Appl. 419 (2006), 180–233. <br><br> Further references can be found <a href="https://drive.google.com/file/d/1Aya0PV0gj4HHnEvq90WzOqrqE9Y1NVcn/view">here</a>.</td>
<td>May 26, 2022 <br><br> 2:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/5cd3c3b4be76a74bafd789129eef93a7_L.jpg"></td>
<td><a href="https://www.gssi.it/people/post-doc/post-doc-maths/item/10533-cifani-paolo">Paolo Cifani</a><br> Gran Sasso Science Institute, Italy</td>
<td><strong>Geometric integration of Lie-Poisson flows on the sphere</strong> <br><br> In this seminar I will touch upon the recent developments in structure-preserving (geometric) integration of Euler’s equations for two-dimensional incompressible flows. It has been known for half a century that the dynamics of incompressible ideal fluids in two dimensions can be understood as an evolution equation on the contangent bundle of the infinite-dimensional Lie group of symplectic dffeomorphisms. In particular, the vorticity equation constitutes a Lie-Poisson system characterized by an infinite number of first integrals, i.e. the integrated powers of vorticity. This set of constraints, absent in three dimensions, has profound effects on the energy transfer mechanisms across scales of motion. Yet, the construction of a numerical system which preserves this rich Poisson structure has been elusive. Most attempts either fail in fully preserving the geometric structure or have a high computational complexity. Here, I will show that, thanks to our recent advances, it possible to design a geometric integrator which embeds this fundamental principle of the continuum into the discrete system at a modest computational cost. The construction of such scheme, the main numerical algorithms and their parallelisation on modern supercomputing facilities will be discussed. Finally, an application to the spectrum of homogeneous two-dimensional turbulence will be illustrated.</td>
<td>May 24, 2022 <br><br> 12:45 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://i1.rgstatic.net/ii/profile.image/951182742806528-1603791046262_Q512/Simone-Camarri.jpg"></td>
<td><a href="https://scholar.google.com/citations?user=FSBvbjMAAAAJ&amp;hl=it">Simone Camarri</a><br> University of Pisa, Italy</td>
<td><strong>Adjoint-based passive control of hydrodynamic instabilities</strong> <br><br> A large number of research papers in the literature have been dedicated to the use of adjoint-based sensitivity and global stability analyses for both characterising and controlling instabilities in fluid mechanics. Such controls, which are mainly passive, are designed for stabilising linearly unstable configurations. The design strategy based on global stability analysis can be rigorously applied to relatively simple flows in laminar regime. More complex configurations can also be rigorously treated, as for instance cases in which the flow to be controlled is time periodic. Moreover, a large interest exists in the application of the same methods for the control of coherent large-scale flow structures in turbulent flows as, for instance, the quasi-periodic shedding of vortices in turbulent wakes. This is possible by postulating the marginal stability of mean flows, which is shown to apply for several cases of interest. In this seminar a review of the methods based on global stability and sensitivity analyses for the design and/or analysis of passive controls will be presented. Moreover, configurations of increasing complexity will be considered, ranging from laminar steady flows to turbulent flows.</td>
<td>May 18, 2022 <br><br> 4:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src=" http://www.mathnet.ru/PersLogos/27986/27986.jpg"></td>
<td><a href="https://sites.google.com/view/lev-lokutsievskiy">Lev Lokutsievskiy</a> <br> Steklov Institute, Moscow, Russia</td>
<td><strong>Asymptotic control theory for affine switching systems of oscillators</strong> <br><br> The talk will be devoted to continuous-time affine control systems and their reachable sets. I will focus on the case when all eigenvalues of the linear part of the system have zero real part. In this case, the reachable sets usually have a non-exponential growth rate as T→∞, and it is usually polynomial. The simplest non-trivial example is the problem of stabilisation (or, conversely, destabilisation) of two pendulums by the same common control. An exact description of reachable sets is most often impossible here, but their asymptotic behaviour as T→∞ can be found with high accuracy. In the talk, I will present the asymptotic behaviour of reachable sets in the problem of controlling a system of N independent oscillators, and in the problem of controlling the wave equation for a closed string. In particular, in these problems the corresponding analog of the Lyapunov function can be found explicitly, and, consequently, the optimal behaviour at high energies can be found very accurately</td>
<td>May 11, 2022 <br><br> 4:30 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="http://www.unige.ch/~hairer/pictures/hai07-2.jpg"></td>
<td><a href="http://www.unige.ch/~hairer/">Ernst Hairer</a> <br> University of Geneva, Switzerland</td>
<td><strong>High order PDE-convergence of ADI-type integrators for parabolic problems</strong><br><br>This work considers space-discretised parabolic problems on a rectangular domain subject to Dirichlet boundary conditions. For the time integration s-stage AMF-W-methods, which are ADI (Alternating Direction Implicit) type integrators, are considered. They are particularly efficient when the space dimension of the problem is large. The classical algebraic conditions for order p (with p&lt;=3) are shown to be sufficient for PDE-convergence of order p (independently of the spatial resolution) in the case of time independent Dirichlet boundary conditions. Under additional conditions, PDE-convergence of order p=3.25-eps for every eps&gt;0 can be obtained. In the case of time dependent boundary conditions there is an order reduction. This is joint work with Severiano Gonzalez-Pinto and Domingo Hernandez-Abreu. Related publications can be downloaded from <a href="http://www.unige.ch/~hairer/preprints.html">http://www.unige.ch/~hairer/preprints.html</a> <br><br> <a href="https://drive.google.com/file/d/1yt5HE0VxulXFmy6Z9tQgfT20S7H1rRsv/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>April 26, 2022 <br><br> 1:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://dmi.units.it/~zennaro/foto_marino380.jpg"></td>
<td><a href="https://dmi.units.it/~zennaro/">Marino Zennaro</a><br> University of Trieste, Italy</td>
<td><strong>Computing antinorms on multicones</strong> <br><br> The theoretical results we consider in this talk may find an interesting application in the study of discrete-time linear switched systems of the form <br> x(n + 1) = A_{σ(n)} x(n), σ : N −→ {1, 2, . . . , m}, <br> where x(0) ∈ R^k, the matrix A_{σ(n)} ∈ R^{k×k} belongs to a finite family F = {A_i}{1≤i≤m} and σ denotes the switching law. <br> It is known that the most stable switching laws are associated to the so-called spectrum-minimizing products of the family F. Moreover, for a normalized family F of matrices (i.e., with lower spectral radius ρˇ(F) = 1) that share an invariant cone K, all the most stable trajectories starting from the interior of K lie on the boundary of the antiball of a so-called invariant Barabanov antinorm, for which a canonical constructive procedure is available (Guglielmi &amp; Z. (2015)). <br> In the particular case of families F sharing an invariant cone K, we show how to provide lower bounds to ˇρ(F) by a suitable adaptation of the Gelfand limit in the framework of antinorms (Guglielmi &amp; Z. (2020)). Then we consider families of matrices F that share an invariant multicone K_{mul} (Brundu &amp; Z. (2018, 2019)) and show how to generalize some of the known results on antinorms to this more general setting (Guglielmi &amp; Z. (in progress)). These generalizations are of interest because common invariant multicones may well exist when common invariant cones do not.</td>
<td>March 31, 2022 <br><br> 2:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="https://istime.math.tecnico.ulisboa.pt/img/GFusco_2009_197x245.jpg"></td>
<td><a href="https://www.researchgate.net/profile/Giorgio-Fusco-4">Giorgio Fusco</a><br> University of L'Aquila, Italy</td>
<td>TBA <br><br></td>
<td>February 24, 2022</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://artscimedia.case.edu/wp-content/uploads/2013/07/03123113/01.jpg"></td>
<td><a href="https://mathstats.case.edu/faculty/erkki-somersalo/">Erkki Somersalo</a><br> Case Western Reserve University, USA</td>
<td><strong>Bayes meets data science to identify changes in brain activity during meditation from MEG measurements</strong> <br><br> Meditation as a potential alternative for pharmaceutical intervention to mitigate conditions such as chronic pain or clinical depression continues to obtain significant attention. One of the problems is that often the positive effects of meditation that have been reported are anecdotal or are based on self reporting. To quantify the effects of meditation, it is therefore important to develop methods based on medical imaging to identify brain regions that are involved in the meditation practice. In this talk, we review some recent results about this topic, addressed by using magnetoencephalography (MEG) to map brain activity during meditation. One of the difficulties here is that the data are less sensitive to activity taking place in the deep brain regions, including the limbic system that is believed to play an important role in meditation. The MEG inverse problem is addressed by using novel Bayesian methods combined with advanced numerical techniques, applied on data from professional Buddhist meditators. The reconstructed activity is then analyzed using data science techniques to distill the information about the activation changes during meditation. <br><br> <a href="https://drive.google.com/file/d/1Sqqmd40RjkqxA8blbK9vV9J9Q1P_D9_N/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>December 16, 2021 <br><br> 3:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Auditorium, Rectorate building</a></td>
</tr>
<tr>
<td><img style="width:60px;" src="http://www.damtp.cam.ac.uk/user/mjc249/images/IMG_0217.jpg"></td>
<td><a href="http://www.damtp.cam.ac.uk/user/mjc249/home.html">Matthew Colbrook</a><br> University of Cambridge, UK</td>
<td><strong>Computing semigroups and time-fractional PDEs with error control</strong> <br><br> We develop an algorithm that computes strongly continuous semigroups on infinite-dimensional Hilbert spaces with explicit error control. Given a generator $A$, a time $t &gt; 0$, an arbitrary initial vector $u_0$ and an error tolerance $\epsilon &gt; 0$, the algorithm computes $\exp(tA)u_0$ with error bounded by $\epsilon$. The (parallelisable) algorithm is based on a combination of a regularized functional calculus, suitable contour quadrature rules and the adaptive computation of resolvents in infinite dimensions. As a particular case, we deal with semigroups on $L^2(R^d)$ that are generated by partial differential operators with polynomially bounded coefficients of locally bounded total variation. For analytic semigroups, we provide a quadrature rule whose error decreases like $\exp(−cN/ log(N))$ for $N$ quadrature points, that remains stable as $N \to \infty$, and which is also suitable for infinite-dimensional operators. Finally, we extend the method to time-fractional PDEs (where it avoids singularities as $t \to  0$ and large memory consumption). Numerical examples are given, including: Schrödinger and wave equations on the aperiodic Ammann–Beenker tiling and fractional beam equations arising in the modelling of small-amplitude vibration of viscoelastic materials. The spectral analysis (which is always needed for contour methods) is considerably simplified due to an infinite-dimensional “solve-then-discretise” approach.</td>
<td>December 1, 2021 <br><br> 5:00 PM <br><br> <a href="https://num-gssi.github.io/venues/">Main Lecture Hall, ex-ISEF building</a></td>
</tr>
</tbody>
</table>
<h3 id="academic-year-202021">Academic Year 2020/21</h3>
<table>
<thead>
<tr>
<th>Speaker</th>
<th></th>
<th>Title, Abstract &amp; Other Info</th>
<th>Date &amp; Venue</th>
</tr>
</thead>
<tbody>
<tr>
<td><img style="width:60px;" src="https://www.math.emory.edu/site/cmds-reuret/author/lars-ruthotto/avatar_hu354b5a1777be32d61e301c15db946272_1009126_270x270_fill_q75_lanczos_center.jpg"></td>
<td><a href="https://www.math.emory.edu/~lruthot/">Lars Ruthotto</a><br> Emory University, USA</td>
<td><strong>Numerical Methods for Deep Learning motivated by Partial Differential Equations</strong> <br><br> Understanding the world through data and computation has always formed the core of scientific discovery. Amid many different approaches, two common paradigms have emerged. On the one hand, primarily data-driven approaches—such as deep neural networks—have proven extremely successful in recent years. Their success is based mainly on their ability to approximate complicated functions with generic models when trained using vast amounts of data and enormous computational resources. But despite many recent triumphs, deep neural networks are difficult to analyze and thus remain mysterious. Most importantly, they lack the robustness, explainability, interpretability, efficiency, and fairness needed for high-stakes decision-making. On the other hand, increasingly realistic model-based approaches—typically derived from first principles and formulated as partial differential equations (PDEs)—are now available for various tasks. One can often calibrate these models—which enable detailed theoretical studies, analysis, and interpretation—with relatively few measurements, thus facilitating their accurate predictions of phenomena. In this talk, I will highlight recent advances and ongoing work to understand and improve deep learning by using techniques from partial differential equations. I will demonstrate how PDE techniques can yield better insight into deep learning algorithms, more robust networks, and more efficient numerical algorithms. I will also expose some of the remaining computational and numerical challenges in this area. <br><br> <a href="https://indico.gssi.it/event/248/attachments/311/509/2021-LRGSSI.pdf">Slides of the talk</a> <br><a href="https://indico.gssi.it/event/248/attachments/311/510/go">Recording of the talk (available to GSSI only)</a></td>
<td>June 17, 2021 <br><br> 4:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://scholar.googleusercontent.com/citations?view_op=view_photo&user=qSl_3FQAAAAJ&citpid=2"></td>
<td><a href="https://researchportal.vub.be/en/persons/ivan-markovsky">Ivan Markovsky</a><br> Vrije Universiteit Brussel, Belgium</td>
<td><strong>Data-driven dynamic interpolation and approximation</strong> <br><br> The behavioral system theory give theoretical foundation for nonparameteric representations of linear time-invariant systems based on Hankel matrices constructed from data. These data-driven representations led in turn to new system identification, signal processing, and control methods. In particular, data-driven simulation and linear quadratic tracking control problems were solved using the new approach [1,2]. This talk shows how the approach can be used further on for solving data-driven interpolation and approximation problems (missing data estimation) and how it can be generalized to some classes of nonlinear systems. The theory leads to algorithms that are both general (can deal simultaneously with missing, exact, and noisy data of multivariable systems) and simple (require existing numerical linear algebra methods only). This opens a practical computational way of doing system theory and signal processing directly from data without identification of a transfer function or a state space representation and doing model-based design. <br><br> [1] I. Markovsky and P. Rapisarda. “Data-driven simulation and control”. Int. J. Control 81.12 (2008), pp. 1946--1959. <br> [2] I. Markovsky. A missing data approach to data-driven filtering and control. IEEE Trans. Automat. Contr., 62:1972--1978, April 2017.<br> [3] I. Markovsky and F. Dörfler. Data-driven dynamic interpolation and approximation. Technical report, Vrije Universiteit Brussel, 2021. <br><br> <a href="https://drive.google.com/file/d/1pt7_SG7n_CUP-f2plfPMVq6TOZ_z5tck/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>March 30, 2021 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/%D0%A2%D1%8B%D1%80%D1%82%D1%8B%D1%88%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2.jpg/270px-%D0%A2%D1%8B%D1%80%D1%82%D1%8B%D1%88%D0%BD%D0%B8%D0%BA%D0%BE%D0%B2.jpg"></td>
<td><a href="https://www.mathnet.ru/eng/person8538">Eugene E. Tyrtyshnikov</a><br> Institute for Numerical Mathematics, Russian Academy of Sciences</td>
<td><strong>Tikhonov's solution to a class of linear systems equivalent within perturbations</strong> <br><br> A standard approach to incorrect problems suggests that a problem of interest is reformulated with the knowledge of some additional a-priori information. This can be done by several well-known regularization techniques. Many practical problems are successfully solved on this way. What does not still look as completely satisfactory is that the new reset problem seems to appear rather implicitly in the very process of its solution. <br> In 1980, A. N. Tikhonov proposed a reformulation [1] that arises explicitly before the discussion of the solution methods. He suggested a notion of normal solution to a family of  linear algebraic systems described by a given individual system and its vicinity comprising perturbed systems, under the assumption that there are compatible systems in the class notwithstanding the compatibility property of the given individual system. Tikhovov proved that the normal solution exists and is unique. However, a natural question about the correctness of the reset problem was not answered. In this talk we address a question of correctness of the reformulated incorrect problems that seems to have been missed in all previous considerations. The main result is the proof of correctness for Tikhonov's normal solution. Possible generalizations and difficulties will be also discussed. <br><br> [1] A. N. Tikhonov, <em>Approximate systems of linear algebraic equations,</em> USSR Computational Mathematics and Mathematical Physics, vol. 20, issue 6 (1980)</td>
<td>March 9, 2021 <br><br> 6:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://michaelschaub.github.io/images/MichaelBW.jpg"></td>
<td><a href="https://michaelschaub.github.io/">Michael Schaub</a> <br> RWTH Aachen  University</td>
<td><strong>Learning from signals on graphs with unobserved edges</strong> <br><br> In many applications we are confronted with the following system identification scenario: we observe a dynamical process that describes the state of a system at particular times. Based on these observations we want to infer the (dynamical) interactions between the entities we observe. In the context of a distributed system, this typically corresponds to a "network identification" task: find the (weighted) edges of the graph of interconnections. However, often the number of samples we can obtain from such a process are far too few to identify the edges of the network exactly. Can we still reliably infer some aspects of the underlying system? <br> Motivated by this question we consider the following identification problem: instead of trying to infer the exact network, we aim to recover a (low-dimensional) statistical model of the network based on the observed signals on the nodes.  More concretely, here we focus on observations that consist of snapshots of a diffusive process that evolves over the unknown network. We model the (unobserved) network as generated from an independent draw from a latent stochastic blockmodel (SBM), and our goal is to infer both the partition of the nodes into blocks, as well as the parameters of this SBM. We present simple spectral algorithms that provably solve the partition and parameter inference problems with high-accuracy. <br> We further discuss some possible variations and extensions of this problem setup. <br><br> <a href="https://drive.google.com/file/d/1OA-4ZXxRBWAbPjbTF-c-TdTfnUAl6Q77/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>February 17, 2021 <br><br> 6:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www-s3-live.kent.edu/s3fs-root/s3fs-public/styles/profile_photo_internal/public/reichel.jpg?itok=BfdERexK"></td>
<td><a href="http://www.math.kent.edu/~reichel/">Lothar Reichel</a><br> Kent State University</td>
<td><strong>Large-scale regression with non-convex loss and penalty</strong> <br><br> We do non-convex optimization with application to image restoration    and regression problems for which a sparse solution is desired.</td>
<td>February 4, 2021 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Anders_C_Hansen_Image.jpg/220px-Anders_C_Hansen_Image.jpg"></td>
<td><a href="http://www.damtp.cam.ac.uk/research/afha/anders/">Anders Hansen</a><br> University of Cambridge, UK</td>
<td><strong>On the foundations of computational mathematics, Smale's 18th problem and the potential limits of AI</strong> <br><br> There is a profound optimism on the impact of deep learning (DL) and AI in the sciences with Geoffrey Hinton concluding that 'They should stop training radiologists now'. However, DL has an Achilles heel: it is universaly unstable so that small changes in the initial data can lead to large errors in the final result. This has been documented in a wide variety of applications. Paradoxically, the existence of stable neural networks for these applications is guaranteed by the celebrated Universal Approximation Theorem, however, the stable neural networks are never computed by the current training approaches. We will address this problem and the potential limitations of AI from a foundations point of view. Indeed, the current situation in AI is comparable to the situation in mathematics in the early 20th century, when David Hilbert’s optimism (typically reflected in his 10th problem) suggested no limitations to what mathematics could prove and no restrictions on what computers could compute. Hilbert’s optimism was turned upside down by Goedel and Turing, who established limitations on what mathematics can prove and which problems computers can solve (however, without limiting the impact of mathematics and computer science).    We predict a similar outcome for modern AI and DL, where the limitations of AI (the main topic of Smale’s 18th problem) will be established through the foundations of computational mathematics. We sketch the beginning of such a program by demonstrating how there exist neural networks approximating classical mappings in scientific computing, however, no algorithm (even randomised) can compute such a network to even 1-digit accuracy (with probability better than 1/2). We will also show how instability is inherit in the methodology of DL demonstrating that there is no easy remedy, given the current methodology. Finally, we will demonstrate basic examples in inverse problems where there exists (untrained) neural networks that can easily compute a solution to the problem, however, the current DL techniques will need 10^80 data points in the training set to get even 1% success rate. <br><br> <a href="https://youtu.be/a-9BFjlCo3Q">Recording of the talk</a></td>
<td>January 28, 2021 <br><br> 3:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://media.licdn.com/dms/image/v2/C5603AQFB4eG-GGbUoQ/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1517245847571?e=2147483647&v=beta&t=K9wFEmSKnTJY-4lXfQJBV32iCBPWLilLU6KkKFAXhro"></td>
<td><a href="https://na.uni-tuebingen.de/~ceruti/">Gianluca Ceruti</a><br> University of Tuebingen</td>
<td><strong>Numerical integrators for dynamical low-rank approximation</strong> <br><br> Discretization of time-dependent high-dimensional PDEs suffers of an undesired effect, known as curse of dimensionality. The amount of data to be stored and treated, grows exponentially, and exceeds standard capacity of common computational devices. <br> In this setting, time dependent model order reductions techniques are desirable. <br> In the present seminar, together with efficient numerical integrators, we present a recently developed approach: dynamical low-rank approximation.  <br> Dynamical low-rank approximation for matrices will be firstly presented, and a numerical integrator with two remarkable properties will be introduced: the matrix projector splitting integrator. <br> Based upon this numerical integrator, we will construct two equivalent extensions for tensors, multi-dimensional arrays, in Tucker format - a high-order generalization of the SVD decomposition for matrices. These extensions are proven to preserve the excellent qualities of the matrix integrator. <br> To conclude, via a novel compact formulation of the Tucker integrator, we will further extend the matrix and Tucker projector splitting integrators to the most general class of Tree Tensor Networks. Important examples belonging to this class and of interest for applications are given, but not only restricted to, by Tensor Trains. <br> This seminar is based upon a joint work with Ch. Lubich and H. Walach.</td>
<td>January 13, 2021 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/171ccfd678ecfd0d1d1085fd8988fdb0_L.jpg"></td>
<td><a href="https://www.gssi.it/people/post-doc/post-doc-maths/item/11289-viguerie-alex">Alexander Viguerie</a><br> GSSI</td>
<td><strong>Efficient, stable, and reliable solvers for the Steady Incompressible Navier-Stokes equations: application to Computational Hemodynamics.</strong> <br><br> Over the past several years, computational fluid dynamics (CFD) simulations have become increasingly popular as a clinical tool for cardiologists at the patient-specific level. The use of CFD in this area poses several challenges. The clinical setting places heavy restrictions on both computational time and power. Simulation results are usually desired within minutes and are usually run on standard computers. For these reasons, steady-state Navier-Stokes simulations are usually preferred, as they can be completed in a fraction of the time required to run an unsteady computation. However, in many respects the steady problem is more difficult than the unsteady one, particularly in regards to solving the associated linear and nonlinear systems. Additionally, boundary data for patient-specific problems is often missing, incomplete, or unreliable. This makes the determination of a useful model challenging, as it requires the generation of reliable boundary data without introducing heavy computational costs. This seminar will address these challenges, as well as some others, and introduce new techniques for workarounds. Results from patient-specific cases will be presented and discussed. <br><br> <a href="https://drive.google.com/file/d/1Ifimam7UsJb5NehcVaumLexxtQpYshdb/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>December 16, 2020 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.tu-chemnitz.de/mathematik/wire/pics/stoll.jpg"></td>
<td><a href="https://www.tu-chemnitz.de/mathematik/wire/prof.php">Martin Stoll</a><br> TU-Chemnitz</td>
<td><strong>From PDEs to data science: an adventure with the graph Laplacian</strong> <br><br> In this talk we briefly review some basic PDE models that are used to model phase separation in materials science. They have since become important tools in image processing and over the last years semi-supervised learning strategies could be implemented with these PDEs at the core. The main ingredient is the graph Laplacian that stems from a graph representation of the data. This matrix is large and typically dense. We illustrate some of its crucial features and show how to efficiently work with the graph Laplacian. In particular, we need some of its eigenvectors and for this the Lanczos process needs to be implemented efficiently. Here, we suggest the use of the NFFT method for evaluating the matrix vector products without even fully constructing the matrix. We illustrate the performance on several examples. <br><br> <a href="https://drive.google.com/file/d/1IzvXmGHpVUlN_f9TCyvP0DokjIN6lvMc/view?usp=sharing">Recording of the talk (available to GSSI only)</a></td>
<td>December 2, 2020 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/ed4443067d9c4194aa38046648597e80_L.jpg"></td>
<td><a href="https://www.gssi.it/people/post-doc/post-doc-maths/item/11206-diaz-de-alba-patricia">Patricia Diaz De Alba</a><br> GSSI</td>
<td><strong>Numerical treatment for inverse electromagnetic problems</strong> <br><br> Electromagnetic induction surveys are among the most popular techniques for non-destructive investigation of soil properties, in order to detect the presence of both ground inhomogeneities and particular substances. Frequency-domain electromagnetic instruments allow the collection of data in different configurations, that is, varying the intercoil spacing, the frequency, and the height above the ground.<br> Based on a non-linear forward model used to describe the interaction between an electromagnetic field and the soil, the aim is to reconstruct the distribution of either the electrical conductivity or the magnetic permeability with respect to depth. To this end, the inversion of both the real (in-phase) and the imaginary (quadrature) components of the signal are studied by a regularized damped Gauss-Newton method. The regularization part of the algorithm is based on a low-rank approximation of the Jacobian of the non-linear model. Furthermore, in many situations, a regularization scheme retrieving smooth solutions is blindly applied, without taking into account the prior available knowledge. An algorithm for a regularization method that promotes the sparsity of the reconstructed electrical conductivity or magnetic permeability distribution is available. This regularization strategy incorporates a minimum gradient support stabilizer into a truncated generalized singular value decomposition scheme. The whole inversion algorithm has been enclosed in a MATLAB package, called FDEMtools, allowing the user to experiment with synthetic and experimental data sets, and different regularization strategies, in order to compare them and draw conclusions.<br> The numerical effectiveness of the inversion procedure is demonstrated on synthetic and real datasets by using FDEMtools package.</td>
<td>November 20, 2020 <br><br> 5:15 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://www.gssi.it/media/k2/items/cache/131afc1cb16b90a10de84b1d079bb47e_L.jpg"></td>
<td><a href="https://na.uni-tuebingen.de/~lubich/">Christian Lubich</a><br> University of Tuebingen</td>
<td><strong>Dynamical low-rank approximation</strong> <br><br> This talk reviews differential equations and their numerical solution on manifolds of low-rank matrices or of tensors with a rank structure such as tensor trains or general tree tensor networks. These low-rank differential equations serve to approximate, in a data-compressed format, large time-dependent matrices and tensors or multivariate functions that are either given explicitly via their increments or are unknown solutions to high-dimensional evolutionary differential equations, with multi-particle time-dependent Schrödinger equations and kinetic equations such as Vlasov equations as noteworthy examples of applications. <br> Recently developed numerical time integrators are  based on splitting the projection onto the tangent space of the low-rank manifold at the current approximation. In contrast to all standard integrators, these projector-splitting methods are robust to the unavoidable presence of small singular values in the low-rank approximation. This robustness relies on exploiting geometric properties of the manifold of low-rank matrices or tensors: in each substep of the projector-splitting algorithm, the approximation moves along a flat subspace of the low-rank manifold. In this way, high curvature due to small singular values does no harm.<br>This talk is based on work done intermittently over the last decade with Othmar Koch, Bart Vandereycken, Ivan Oseledets, Emil Kieri, Hanna Walach and Gianluca Ceruti.</td>
<td>November 18, 2020 <br><br> 5:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="http://people.disim.univaq.it/~raffaele.dambrosio/Raf.png"/></td>
<td><a href="http://people.disim.univaq.it/~raffaele.dambrosio/">Raffaele D'Ambrosio</a><br> University of L'Aquila</td>
<td><strong>Structure-preserving numerics for stochastic differential equations</strong> <br><br> Modern Numerical Analysis is not only devoted to accurately approximating the solutions of various problems through efficient and robust schemes, but also to retaining qualitative properties of the continuous problem over long times. Sometimes such conservation properties naturally characterize the numerical schemes, while in more complex situations preservation issues have to be conveyed into the numerical approximations. The talk is focused on presenting recent advances in structure-preservation issues for selected stochastic differential equations satisfying some characteristic invariance laws. The behaviour of stochastic multistep methods in the preservation of mean-square contractivity will be analyzed; we show, in this case, that conservation properties are hidden, as a matter of fact, into conditional stability properties of numerical schemes. The analysis will also be conveyed to the discretization of stochastic Hamiltonian problems for the numerical preservation of the behaviour of the expected Hamiltonian. The theoretical analysis will also be supported by the numerical evidence.</td>
<td>November 4, 2020 <br><br> 3:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="https://baggiogi.github.io/images/Myself.jpg"/></td>
<td><a href="https://baggiogi.github.io/">Giacomo Baggio</a><br> University of Padua</td>
<td><strong>From Model-Based to Data-Driven Control of Network Dynamics</strong> <br><br> The control of complex dynamical networks has attracted increasing interest over the past few years, with reference, in particular, to problems of controllability, optimal input design, and minimal actuator placement. In this talk, I will address the problem of controlling linear dynamical networks from a control-energy or "practical" perspective. I will first focus on the model-based scenario and review the fundamental metrics, theoretical limitations, and challenges in controlling networks using a limited number of control nodes. In particular, I will emphasize the impact of the "degree" of non-normality of the network's adjacency matrix on the control performance. Then, I will switch to a data-driven scenario, and show how some network control problems can be efficiently solved by relying on experimental data only. <br><br> <a href="/docs/talk_gssi_baggio.pdf">Slides of the seminar</a></td>
<td>October 14, 2020 <br><br> 4:00 PM</td>
</tr>
<tr>
<td><img style="width:60px;" src="http://pages.di.unipi.it/fpoloni/me/picture_2018_PEVA.jpg"></td>
<td><a href="http://pages.di.unipi.it/fpoloni/index.html">Federico Poloni</a><br> University of Pisa</td>
<td><strong>Inverses of quasidefinite matrices in block-factored form, with an application to control theory</strong> <br> <em>joint work with P. Benner</em> <br><br> We describe an algorithm to compute the explicit inverse of a dense quasi-definite matrix, i.e., a symmetric matrix of the form [-BB^T, A; A^T, C^TC], with the (1,1) block negative semidefinite and the (2,2) block positive semidefinite. The algorithm is a variant of Gauss-Jordan elimination that works on the low-rank factors $B$ and $C$ directly without ever forming those blocks. The individual elimination steps amount to a transformation called <em>principal pivot transform</em>; it was shown in [Poloni, Strabic 2016] how to perform it by working only on $A, B, C$, and we rely on that procedure here. We discuss the stability of the resulting method, and show how the algorithm (and in particular the produced low-rank factors) can be of use in control theory, in the context of the matrix sign iteration, which is a method used to solve algebraic Riccati equations.</td>
<td>September 30, 2020 <br><br> 4:00 PM</td>
</tr>
</tbody>
</table></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        <!-- 
        <hr>
        <p>
        <small>Made with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
        </p>

        
         -->
    </footer>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = ".."</script>
    
    <script src="../js/base.js"></script>
    <script src="../assets/mathjaxhelper.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.2/highlight.min.js"></script>
    <script src="../assets/config.js"></script>
    <script src="../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
