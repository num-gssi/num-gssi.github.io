{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Numerical Analysis and Data Science Group Gran Sasso Science Institute This is the homepage of the Numerical Analysis and Data Science Group at Gran Sasso Science Institute . The group's interests center around numerical methods for differential equations and dynamical systems, numerical linear algebra, matrix theory, optimization and their application to the analysis of graphs and networks and to problems related to learning from data.","title":"Home"},{"location":"people/","text":"Faculty Nicola Guglielmi Nicola Gugliemi is full professor in Numerical Analysis and Chair of the Doctoral School in Mathematics at GSSI. He is interested in the general area of scientific computing, particularly numerical analysis of ordinary and delay differential equations, stability analysis of (discretized) dynamical systems - including variable coefficient and switched systems - and ode methods in matrix perturbation theory and control, for high-dimensional problems. More specifically: Stiff and singularly perturbed problems (in particular in the framework of delay differential equations); software development for general classes of implicit delay differential equations; stability analysis of numerical integrators for ordinary and delay differential equations; computation of the joint spectral characteristics of a set of matrices, with application to contractivity analysis of time dependent systems of differential and difference equations; ode-based pseudospectral computations for both unstructured and structured problems; non-smooth analysis of discontinuous differential equations with focus on the computation of weak solutions. Personal Web Page Francesco Tudisco Francesco Tudisco is assistant professor in the School of Mathematics at GSSI. His research interests lie at the intersection between matrix theory, scientific computing, network analysis and machine learning. In particular, some of the fields he is currently working on are: higher-order data mining, spectral methods for unsupervised and semi-supervised learning, community and core-periphery detection in networks, spectral theory for discrete graphs, nonlinear Perron-Frobenius theory, tensor methods and tensor eigenvectors, multilayer graph clustering and centrality. Before moving to the GSSI, Francesco was a Marie Curie Individual Fellow at the University of Strathclyde, Glasgow (UK), working on the project: MAGNET: Models and algorithms for graph centrality based on nonlinear eigenvalue techniques . Prior to that, he held research assistant positions at Saarland University (Germany) and University of Padua (Italy). He obtained his PhD in Mathematics in 2015 from the University of Rome Tor Vergata (Italy). Personal Web Page. Postdocs No\u00e8 Angelo Caruso I'm a recent PhD graduate in Mathematical Analysis, Modelling and Applications at the International School of Advanced Studies (SISSA) in Trieste. My current position is as a postdoctoral researcher at the Gran Sasso Science Institute (GSSI) in L'Aquila. My research interests are in operator theory and abstract approximation theory, taking inspiration from topics in theoretical numerical analysis with a particular emphasis on underlying functional analytic aspects. My thesis topic focused on Krylov subspace methods and projection methods and was supervised by Prof. Alessandro Michelangeli (SISSA) and Prof. Paolo Novati (University of Trieste). Patricia Diaz de Alba Patricia Diaz de Alba has obtained her PhD in Numerical Analysis at the Department of Mathematics and Computer Science of the University of Cagliari (Italy) in 2017. She has been a Postdoctoral Researcher at the same University from 2017 until 2020. Currently, she has a postdoctoral research position at the Gran Sasso Scientific Institute (GSSI) in L'Aquila (Italy). Her main research interest is in inverse problems and is focused on, but not limited to, image restoration in applied Geophysics. This research involves the application of techniques concerned with numerical linear algebra, optimization, and the solution of these inverse problems. Over the past few years, she has worked on several problems including regularization methods, ill-posed problems, and numerical and computational methods for integral and partial differential equations. Personal Web Page Alexander Viguerie My research lies at the intersection of numerical analysis and engineering, where I focus on the use of numerical simulations to answer questions arising from engineering applications. My work encompasses many aspects of these problems, including the development of new physical models and of new algorithms to enable their accurate and efficient numerical solution. In terms of applications, I have a specific interest in cardiological problems, where I have collaborated extensively with medical doctors and engineers to provide solutions to problems of clinical interest. I am also interested in the mathematical modeling of epidemics in space and time; the ultimate goal of this research is to aid public health decision-makers. My approach to this problem draws heavily on my experience in continuum mechanics, and I believe these principles can be applied further to solve problems arising from the life sciences. From the mathematical point of view, this work is heavily concentrated in the area of numerical partial differential equations and finite element methods. As much of this work naturally leads to numerical linear algebra, I am also interested in the development of preconditioning and inexact algebraic factorization methods for the numerical solution of partial differential equations. PhD Students Dayana Savostianova Dayana Savostianova is a PhD Student in Mathematics in Natural, Social and Life Sciences, GSSI. Previously, she was a Research Intern at the Complex Systems Modelling and Control Laboratory, Department of Computer Sciences, Higher School of Economics (Moscow, Russia). She holds a BSc in Applied Mathematics and Information Science from Higher School of Economics. Her current research interests are in the scope of complex systems, mathematical modelling and direct numerical simulations of natural processes. Her previous work was focused on predictability in Self-Organised Criticality systems. Miryam Gnazzo Miryam Gnazzo is a PhD student in Mathematics at the GSSI in L\u2019Aquila. She holds a MSc in Mathematics from the University of Pisa, with a thesis about a resultant-based method for bivariate rootfinding. Her current research interests are in the field of numerical linear algebra, particularly in multivariate polynomial rootfinding. Stefano Sicilia Stefano Sicilia is a PhD Student in Mathematics in Natural, Social and Life Sciences at GSSI. He studied Mathematics at the University of Pisa both for Bachelor\u2019s and Master\u2019s degrees, focusing on applied mathematics, numerical analysis and data science. His Master\u2019s degree thesis deals with numerical methods for polynomial root-finding. His current research interests are numeric linear algebra, polynomial root-finding and numerical methods for differential equations. Anton Savostianov Anton Savostianov is a PhD Student in Mathematics in Natural, Social and Life Sciences, GSSI. Previously, he was a Research Intern at the Complex Systems Modelling and Control Laboratory, Department of Computer Sciences, Higher School of Economics (Moscow, Russia). He holds a MSc in Data Analysis in Biology and Medicine (sc. advisor - Mikhail Gelfand) and BSc in Applied Mathematics and Informatics from Higher School of Economics. His current research interests are in the scope of complex systems, mathematical modelling in solar activity, nonlinear coupled oscillators and its bifurcations. Published an article in Physica D, oral report at Space Climate 7 conference (Montreal, Canada, 2019). Konstantin Prokopchik My name is Prokopchik Konstantin. I am from Russia. I received my bachelor\u2019s degree in 2016 in Math\u2019s, the work topic was about modelling the fracture in oil industry. Then I found out about the new master program in my university, that was launching in 2016. It\u2019s called Big Data Analytics, but essentially, it\u2019s just Computer Science. In master\u2019s thesis I gathered a specific dataset of melodies, tried to observe and test a lot of systems that generate music and attempted to create a new one. Apart from studying, I\u2019ve been working as a python programmer for the last year. I\u2019ve played with different NLP tools, worked with plenty of AWS\u2019s, Jenkins and I\u2019m sure I will continue to explore a lot of things around this field. Mattia Manucci I am a PhD Research Fellow in Applied Mathematics at the GSSI. Previously, I was a student of Mathematical engineering at the Politecnico di Torino. I hold a Master degree in Mathematical engineering and a Master 2 in Computational Mechanics taken at the Ecole Centrale de Nantes, France. I am interested in the applied branches of Mathematics especially the one concerning the numerical analysis.","title":"People"},{"location":"people/#faculty","text":"","title":"Faculty"},{"location":"people/#nicola-guglielmi","text":"Nicola Gugliemi is full professor in Numerical Analysis and Chair of the Doctoral School in Mathematics at GSSI. He is interested in the general area of scientific computing, particularly numerical analysis of ordinary and delay differential equations, stability analysis of (discretized) dynamical systems - including variable coefficient and switched systems - and ode methods in matrix perturbation theory and control, for high-dimensional problems. More specifically: Stiff and singularly perturbed problems (in particular in the framework of delay differential equations); software development for general classes of implicit delay differential equations; stability analysis of numerical integrators for ordinary and delay differential equations; computation of the joint spectral characteristics of a set of matrices, with application to contractivity analysis of time dependent systems of differential and difference equations; ode-based pseudospectral computations for both unstructured and structured problems; non-smooth analysis of discontinuous differential equations with focus on the computation of weak solutions. Personal Web Page","title":"Nicola Guglielmi"},{"location":"people/#francesco-tudisco","text":"Francesco Tudisco is assistant professor in the School of Mathematics at GSSI. His research interests lie at the intersection between matrix theory, scientific computing, network analysis and machine learning. In particular, some of the fields he is currently working on are: higher-order data mining, spectral methods for unsupervised and semi-supervised learning, community and core-periphery detection in networks, spectral theory for discrete graphs, nonlinear Perron-Frobenius theory, tensor methods and tensor eigenvectors, multilayer graph clustering and centrality. Before moving to the GSSI, Francesco was a Marie Curie Individual Fellow at the University of Strathclyde, Glasgow (UK), working on the project: MAGNET: Models and algorithms for graph centrality based on nonlinear eigenvalue techniques . Prior to that, he held research assistant positions at Saarland University (Germany) and University of Padua (Italy). He obtained his PhD in Mathematics in 2015 from the University of Rome Tor Vergata (Italy). Personal Web Page.","title":"Francesco Tudisco"},{"location":"people/#postdocs","text":"","title":"Postdocs"},{"location":"people/#noe-angelo-caruso","text":"I'm a recent PhD graduate in Mathematical Analysis, Modelling and Applications at the International School of Advanced Studies (SISSA) in Trieste. My current position is as a postdoctoral researcher at the Gran Sasso Science Institute (GSSI) in L'Aquila. My research interests are in operator theory and abstract approximation theory, taking inspiration from topics in theoretical numerical analysis with a particular emphasis on underlying functional analytic aspects. My thesis topic focused on Krylov subspace methods and projection methods and was supervised by Prof. Alessandro Michelangeli (SISSA) and Prof. Paolo Novati (University of Trieste).","title":"No\u00e8 Angelo Caruso"},{"location":"people/#patricia-diaz-de-alba","text":"Patricia Diaz de Alba has obtained her PhD in Numerical Analysis at the Department of Mathematics and Computer Science of the University of Cagliari (Italy) in 2017. She has been a Postdoctoral Researcher at the same University from 2017 until 2020. Currently, she has a postdoctoral research position at the Gran Sasso Scientific Institute (GSSI) in L'Aquila (Italy). Her main research interest is in inverse problems and is focused on, but not limited to, image restoration in applied Geophysics. This research involves the application of techniques concerned with numerical linear algebra, optimization, and the solution of these inverse problems. Over the past few years, she has worked on several problems including regularization methods, ill-posed problems, and numerical and computational methods for integral and partial differential equations. Personal Web Page","title":"Patricia Diaz de Alba"},{"location":"people/#alexander-viguerie","text":"My research lies at the intersection of numerical analysis and engineering, where I focus on the use of numerical simulations to answer questions arising from engineering applications. My work encompasses many aspects of these problems, including the development of new physical models and of new algorithms to enable their accurate and efficient numerical solution. In terms of applications, I have a specific interest in cardiological problems, where I have collaborated extensively with medical doctors and engineers to provide solutions to problems of clinical interest. I am also interested in the mathematical modeling of epidemics in space and time; the ultimate goal of this research is to aid public health decision-makers. My approach to this problem draws heavily on my experience in continuum mechanics, and I believe these principles can be applied further to solve problems arising from the life sciences. From the mathematical point of view, this work is heavily concentrated in the area of numerical partial differential equations and finite element methods. As much of this work naturally leads to numerical linear algebra, I am also interested in the development of preconditioning and inexact algebraic factorization methods for the numerical solution of partial differential equations.","title":"Alexander Viguerie"},{"location":"people/#phd-students","text":"","title":"PhD Students"},{"location":"people/#dayana-savostianova","text":"Dayana Savostianova is a PhD Student in Mathematics in Natural, Social and Life Sciences, GSSI. Previously, she was a Research Intern at the Complex Systems Modelling and Control Laboratory, Department of Computer Sciences, Higher School of Economics (Moscow, Russia). She holds a BSc in Applied Mathematics and Information Science from Higher School of Economics. Her current research interests are in the scope of complex systems, mathematical modelling and direct numerical simulations of natural processes. Her previous work was focused on predictability in Self-Organised Criticality systems.","title":"Dayana Savostianova"},{"location":"people/#miryam-gnazzo","text":"Miryam Gnazzo is a PhD student in Mathematics at the GSSI in L\u2019Aquila. She holds a MSc in Mathematics from the University of Pisa, with a thesis about a resultant-based method for bivariate rootfinding. Her current research interests are in the field of numerical linear algebra, particularly in multivariate polynomial rootfinding.","title":"Miryam Gnazzo"},{"location":"people/#stefano-sicilia","text":"Stefano Sicilia is a PhD Student in Mathematics in Natural, Social and Life Sciences at GSSI. He studied Mathematics at the University of Pisa both for Bachelor\u2019s and Master\u2019s degrees, focusing on applied mathematics, numerical analysis and data science. His Master\u2019s degree thesis deals with numerical methods for polynomial root-finding. His current research interests are numeric linear algebra, polynomial root-finding and numerical methods for differential equations.","title":"Stefano Sicilia"},{"location":"people/#anton-savostianov","text":"Anton Savostianov is a PhD Student in Mathematics in Natural, Social and Life Sciences, GSSI. Previously, he was a Research Intern at the Complex Systems Modelling and Control Laboratory, Department of Computer Sciences, Higher School of Economics (Moscow, Russia). He holds a MSc in Data Analysis in Biology and Medicine (sc. advisor - Mikhail Gelfand) and BSc in Applied Mathematics and Informatics from Higher School of Economics. His current research interests are in the scope of complex systems, mathematical modelling in solar activity, nonlinear coupled oscillators and its bifurcations. Published an article in Physica D, oral report at Space Climate 7 conference (Montreal, Canada, 2019).","title":"Anton Savostianov"},{"location":"people/#konstantin-prokopchik","text":"My name is Prokopchik Konstantin. I am from Russia. I received my bachelor\u2019s degree in 2016 in Math\u2019s, the work topic was about modelling the fracture in oil industry. Then I found out about the new master program in my university, that was launching in 2016. It\u2019s called Big Data Analytics, but essentially, it\u2019s just Computer Science. In master\u2019s thesis I gathered a specific dataset of melodies, tried to observe and test a lot of systems that generate music and attempted to create a new one. Apart from studying, I\u2019ve been working as a python programmer for the last year. I\u2019ve played with different NLP tools, worked with plenty of AWS\u2019s, Jenkins and I\u2019m sure I will continue to explore a lot of things around this field.","title":"Konstantin Prokopchik"},{"location":"people/#mattia-manucci","text":"I am a PhD Research Fellow in Applied Mathematics at the GSSI. Previously, I was a student of Mathematical engineering at the Politecnico di Torino. I hold a Master degree in Mathematical engineering and a Master 2 in Computational Mechanics taken at the Ecole Centrale de Nantes, France. I am interested in the applied branches of Mathematics especially the one concerning the numerical analysis.","title":"Mattia Manucci"},{"location":"reading_group/","text":"COMPiLE Reading Group We organize a reading group on COMPutational LEarning , specifically on topics related to Numerics/Matrix Theory/Graph Theory with particular emphasis on their application/connection with Machine Learning, Data Mining and Network Science. We meet regularly to read a paper of common interest, together, with the goal of creating some motivation for staying up to date with the new papers or to catch up with some papers that you wanted to read but postponed for some time. The meetings will take place in the Main Lecture Hall on Wednesdays, starting at around 16:30-17:00. In person participation is highly encouraged (if the numbers will allow that), but there will be the possibility to join also via zoom. If you are interested in participating please complete the form below until October 31 to be to be notified about the first meeting (the form will continue working after that): Google Form: Subscription to Reading Group mailing list If you have suggestions for papers to ready you can propose your ideas here: Google Form: Suggestions for papers to read The reading group is organized by our early career group members and supervised/coordinated by Nicola Guglielmi and Francesco Tudisco . Organizer Period Dayana Savostianova , GSSI November 2021 -- present Presenter Title, Abstract & Other Info Date Giuseppe Lipardi Computing semiclassical quantum dynamics with Hagedorn wavepackets, Erwan Faou, Vasile Gradinaru, and Christian Lubich We consider the approximation of multiparticle quantum dynamics in the semiclassical regime by Hagedorn wavepackets, which are products of complex Gaussians with polynomials that form an orthonormal $L^2$ basis and preserve their type under propagation in Schr\u00f6dinger equations with quadratic potentials. We build a fully explicit, time-reversible time-stepping algorithm to approximate the solution of the Hagedorn wavepacket dynamics. The algorithm is based on a splitting between the kinetic and potential part of the Hamiltonian operator, as well as on a splitting of the potential into its local quadratic approximation and the remainder. The algorithm is robust in the semiclassical limit. It reduces to the Strang splitting of the Schr\u00f6dinger equation in the limit of the full basis set, and it advances positions and momenta by the St\u00f6rmer\u2013Verlet method for the classical equations of motion. The algorithm allows for the treatment of multiparticle problems by thinning out the basis according to a hyperbolic cross approximation and of high-dimensional problems by Hartree-type approximations in a moving coordinate frame. link March 30, 2022 Martino Caliaro Stability analysis of a chain of non-identical vehicles under bilateral cruise control Bilateral cruise control (BCC) suppresses traffic flow instabilities. Previously, for simplicity of analysis, vehicles in BCC traffic flow were assumed to be identical, i.e., using the same gains for control. In this study, we analyze the stability of an inhomogeneous vehicular chain in which the gains used by different vehicles are not the same. Not unexpectedly, mathematical analysis becomes more difficult, and leads to a quadratic eigenvalue problem. We study several different cases, and shows that a chain of vehicles under bilateral cruise control is stable even when the vehicles do not all have the same control system properties. Numerical simulations validate the analysis. http://eprints.maths.manchester.ac.uk/2688/1/wtsh19.pdf March 23, 2022 Vishnu Sanjay Hodge Laplacians on Graphs, Lek-Heng Lim This is an elementary introduction to the Hodge Laplacian on a graph, a higher-order generalization of the graph Laplacian. We will discuss basic properties including cohomology and Hodge theory. The main feature of our approach is simplicity, requiring only knowledge of linear algebra and graph theory. We have also isolated the algebra from the topology to show that a large part of cohomology and Hodge theory is nothing more than the linear algebra of matrices satisfying AB=0. For the remaining topological aspect, we cast our discussions entirely in terms of graphs as opposed to less-familiar topological objects like simplicial complexes. https://arxiv.org/abs/1507.05379 March 16, 2022 Helena Biscevic Time-symmetric integration in astrophysics Calculating the long term solution of ordinary differential equations, such as those of the N-body problem, is central to understanding a wide range of dynamics in astrophysics, from galaxy formation to planetary chaos. Because generally no analytic solution exists to these equations, researchers rely on numerical methods which are prone to various errors. In an effort to mitigate these errors, powerful symplectic integrators have been employed. But symplectic integrators can be severely limited because they are not compatible with adaptive stepping and thus they have difficulty accommodating changing time and length scales. A promising alternative is time-reversible integration, which can handle adaptive time stepping, but the errors due to time-reversible integration in astrophysics are less understood. The goal of this work is to study analytically and numerically the errors caused by time-reversible integration, with and without adaptive stepping. We derive the modified differential equations of these integrators to perform the error analysis. As an example, we consider the trapezoidal rule, a reversible non-symplectic integrator, and show it gives secular energy error increase for a pendulum problem and for a H\u00e9non---Heiles orbit. We conclude that using reversible integration does not guarantee good energy conservation and that, when possible, use of symplectic integrators is favored. We also show that time-symmetry and time-reversibility are properties that are distinct for an integrator. https://arxiv.org/abs/1708.07266 March 8, 2022 Pierpaolo Bilotto On the spectra of general random graphs, Fan Chung and Mary Radcliffe We consider random graphs such that each edge is determined by an independent random variable, where the probability of each edge is not assumed to be equal. We use a Chernoff inequality for matrices to show that the eigenvalues of the adjacency matrix and the normalized Laplacian of such a random graph can be approximated by those of the weighted expectation graph, with error bounds dependent upon the minimum and maximum expected degrees. In particular, we use these results to bound the spectra of random graphs with given expected degree sequences, including random power law graphs. Moreover, we prove a similar result giving concentration of the spectrum of a matrix martingale on its expectation. https://www.combinatorics.org/ojs/index.php/eljc/article/view/v18i1p215 March 2, 2022 Mattia Manucci Physics-informed machine learning for reduced-order modeling of nonlinear problems A reduced basis method based on a physics-informed machine learning framework is developed for efficient reduced-order modeling of parametrized partial differential equations (PDEs). A feedforward neural network is used to approximate the mapping from the time-parameter to the reduced coefficients. During the offline stage, the network is trained by minimizing the weighted sum of the residual loss of the reduced-order equations, and the data loss of the labeled reduced coefficients that are obtained via the projection of high-fidelity snapshots onto the reduced space. Such a network is referred to as physics-reinforced neural network (PRNN). As the number of residual points in time-parameter space can be very large, an accurate network \u2013 referred to as physics-informed neural network (PINN) \u2013 can be trained by minimizing only the residual loss. However, for complex nonlinear problems, the solution of the reduced-order equation is less accurate than the projection of high-fidelity solution onto the reduced space. Therefore, the PRNN trained with the snapshot data is expected to have higher accuracy than the PINN. Numerical results demonstrate that the PRNN is more accurate than the PINN and a purely data-driven neural network for complex problems. During the reduced basis refinement, the PRNN may obtain higher accuracy than the direct reduced-order model based on a Galerkin projection. The online evaluation of PINN/PRNN is orders of magnitude faster than that of the Galerkin reduced-order model. link Feb 23, 2022 Tommaso Tonolo Mean Field Analysis of Hypergraph Contagion Model, Desmond J. Higham and Henry-Louis de Kergorlay We typically interact in groups, not just in pairs. For this reason, it has recently been proposed that the spread of information, opinion or disease should be modelled over a hypergraph rather than a standard graph. The use of hyperedges naturally allows for a nonlinear rate of transmission, in terms of both the group size and the number of infected group members, as is the case, for example, when social distancing is encouraged. We consider a general class of individual-level, stochastic, susceptible-infected-susceptible models on a hypergraph, and focus on a mean field approximation proposed in [Arruda et al., Phys. Rev. Res., 2020]. We derive spectral conditions under which the mean field model predicts local or global stability of the infection-free state. We also compare these results with (a) a new condition that we derive for decay to zero in mean for the exact process, (b) conditions for a different mean field approximation in [Higham and de Kergorlay, Proc. Roy. Soc. A, 2021], and (c) numerical simulations of the microscale model. https://arxiv.org/abs/2108.05451 Feb 23, 2022 Arturo De Marinis Regularized nonlinear acceleration, by Damien Scieur, Alexandre d\u2019Aspremont, Francis Bach We describe a convergence acceleration technique for unconstrained optimization problems. Our scheme computes estimates of the optimum from a nonlinear average of the iterates produced by any optimization method. The weights in this average are computed via a simple linear system, whose solution can be updated online. This acceleration scheme runs in parallel to the base algorithm, providing improved estimates of the solution on the fly, while the original optimization method is running. Numerical experiments are detailed on classical classification problems. https://arxiv.org/abs/1606.04133 Feb 9, 2022 Konstantin Prokopchik Consensus Dynamics and Opinion Formation on Hypergraphs In this chapter, we derive and analyse models for consensus dynamics on hypergraphs. As we discuss, unless there are nonlinear node interaction functions, it is always possible to rewrite the system in terms of a new network of effective pairwise node interactions, regardless of the initially underlying multi-way interaction structure. We thus focus on dynamics based on a certain class of non-linear interaction functions, which can model different sociological phenomena such as peer pressure and stubbornness. Unlike for linear consensus dynamics on networks, we show how our nonlinear model dynamics can cause shifts away from the average system state. We examine how these shifts are influenced by the distribution of the initial states, the underlying hypergraph structure and different forms of non-linear scaling of the node interaction function. https://arxiv.org/abs/2105.01369 Jan 26, 2022 Simone Fioravanti EigenGame: PCA as Nash Equilibrium We present a novel view on principal component analysis (PCA) as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm -- which combines elements from Oja's rule with a generalized Gram-Schmidt orthogonalization -- is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights. ICLR 2021 - https://arxiv.org/abs/2010.00554 Dec 9, 2021 Dayana Savostianova Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching Data Poisoning attacks modify training data to maliciously control a model trained on such data. In this work, we focus on targeted poisoning attacks which cause a reclassification of an unmodified test image and as such breach model integrity. We consider a particularly malicious poisoning attack that is both \"from scratch\" and \"clean label\", meaning we analyze an attack that successfully works against new, randomly initialized models, and is nearly imperceptible to humans, all while perturbing only a small fraction of the training data. Previous poisoning attacks against deep neural networks in this setting have been limited in scope and success, working only in simplified settings or being prohibitively expensive for large datasets. The central mechanism of the new attack is matching the gradient direction of malicious examples. We analyze why this works, supplement with practical considerations. and show its threat to real-world practitioners, finding that it is the first poisoning method to cause targeted misclassification in modern deep networks trained from scratch on a full-sized, poisoned ImageNet dataset. Finally we demonstrate the limitations of existing defensive strategies against such an attack, concluding that data poisoning is a credible threat, even for large-scale deep learning systems. ICLR 2021 - https://arxiv.org/abs/2009.02276 November 24, 2021","title":"Reading group"},{"location":"reading_group/#compile-reading-group","text":"We organize a reading group on COMPutational LEarning , specifically on topics related to Numerics/Matrix Theory/Graph Theory with particular emphasis on their application/connection with Machine Learning, Data Mining and Network Science. We meet regularly to read a paper of common interest, together, with the goal of creating some motivation for staying up to date with the new papers or to catch up with some papers that you wanted to read but postponed for some time. The meetings will take place in the Main Lecture Hall on Wednesdays, starting at around 16:30-17:00. In person participation is highly encouraged (if the numbers will allow that), but there will be the possibility to join also via zoom. If you are interested in participating please complete the form below until October 31 to be to be notified about the first meeting (the form will continue working after that): Google Form: Subscription to Reading Group mailing list If you have suggestions for papers to ready you can propose your ideas here: Google Form: Suggestions for papers to read The reading group is organized by our early career group members and supervised/coordinated by Nicola Guglielmi and Francesco Tudisco . Organizer Period Dayana Savostianova , GSSI November 2021 -- present Presenter Title, Abstract & Other Info Date Giuseppe Lipardi Computing semiclassical quantum dynamics with Hagedorn wavepackets, Erwan Faou, Vasile Gradinaru, and Christian Lubich We consider the approximation of multiparticle quantum dynamics in the semiclassical regime by Hagedorn wavepackets, which are products of complex Gaussians with polynomials that form an orthonormal $L^2$ basis and preserve their type under propagation in Schr\u00f6dinger equations with quadratic potentials. We build a fully explicit, time-reversible time-stepping algorithm to approximate the solution of the Hagedorn wavepacket dynamics. The algorithm is based on a splitting between the kinetic and potential part of the Hamiltonian operator, as well as on a splitting of the potential into its local quadratic approximation and the remainder. The algorithm is robust in the semiclassical limit. It reduces to the Strang splitting of the Schr\u00f6dinger equation in the limit of the full basis set, and it advances positions and momenta by the St\u00f6rmer\u2013Verlet method for the classical equations of motion. The algorithm allows for the treatment of multiparticle problems by thinning out the basis according to a hyperbolic cross approximation and of high-dimensional problems by Hartree-type approximations in a moving coordinate frame. link March 30, 2022 Martino Caliaro Stability analysis of a chain of non-identical vehicles under bilateral cruise control Bilateral cruise control (BCC) suppresses traffic flow instabilities. Previously, for simplicity of analysis, vehicles in BCC traffic flow were assumed to be identical, i.e., using the same gains for control. In this study, we analyze the stability of an inhomogeneous vehicular chain in which the gains used by different vehicles are not the same. Not unexpectedly, mathematical analysis becomes more difficult, and leads to a quadratic eigenvalue problem. We study several different cases, and shows that a chain of vehicles under bilateral cruise control is stable even when the vehicles do not all have the same control system properties. Numerical simulations validate the analysis. http://eprints.maths.manchester.ac.uk/2688/1/wtsh19.pdf March 23, 2022 Vishnu Sanjay Hodge Laplacians on Graphs, Lek-Heng Lim This is an elementary introduction to the Hodge Laplacian on a graph, a higher-order generalization of the graph Laplacian. We will discuss basic properties including cohomology and Hodge theory. The main feature of our approach is simplicity, requiring only knowledge of linear algebra and graph theory. We have also isolated the algebra from the topology to show that a large part of cohomology and Hodge theory is nothing more than the linear algebra of matrices satisfying AB=0. For the remaining topological aspect, we cast our discussions entirely in terms of graphs as opposed to less-familiar topological objects like simplicial complexes. https://arxiv.org/abs/1507.05379 March 16, 2022 Helena Biscevic Time-symmetric integration in astrophysics Calculating the long term solution of ordinary differential equations, such as those of the N-body problem, is central to understanding a wide range of dynamics in astrophysics, from galaxy formation to planetary chaos. Because generally no analytic solution exists to these equations, researchers rely on numerical methods which are prone to various errors. In an effort to mitigate these errors, powerful symplectic integrators have been employed. But symplectic integrators can be severely limited because they are not compatible with adaptive stepping and thus they have difficulty accommodating changing time and length scales. A promising alternative is time-reversible integration, which can handle adaptive time stepping, but the errors due to time-reversible integration in astrophysics are less understood. The goal of this work is to study analytically and numerically the errors caused by time-reversible integration, with and without adaptive stepping. We derive the modified differential equations of these integrators to perform the error analysis. As an example, we consider the trapezoidal rule, a reversible non-symplectic integrator, and show it gives secular energy error increase for a pendulum problem and for a H\u00e9non---Heiles orbit. We conclude that using reversible integration does not guarantee good energy conservation and that, when possible, use of symplectic integrators is favored. We also show that time-symmetry and time-reversibility are properties that are distinct for an integrator. https://arxiv.org/abs/1708.07266 March 8, 2022 Pierpaolo Bilotto On the spectra of general random graphs, Fan Chung and Mary Radcliffe We consider random graphs such that each edge is determined by an independent random variable, where the probability of each edge is not assumed to be equal. We use a Chernoff inequality for matrices to show that the eigenvalues of the adjacency matrix and the normalized Laplacian of such a random graph can be approximated by those of the weighted expectation graph, with error bounds dependent upon the minimum and maximum expected degrees. In particular, we use these results to bound the spectra of random graphs with given expected degree sequences, including random power law graphs. Moreover, we prove a similar result giving concentration of the spectrum of a matrix martingale on its expectation. https://www.combinatorics.org/ojs/index.php/eljc/article/view/v18i1p215 March 2, 2022 Mattia Manucci Physics-informed machine learning for reduced-order modeling of nonlinear problems A reduced basis method based on a physics-informed machine learning framework is developed for efficient reduced-order modeling of parametrized partial differential equations (PDEs). A feedforward neural network is used to approximate the mapping from the time-parameter to the reduced coefficients. During the offline stage, the network is trained by minimizing the weighted sum of the residual loss of the reduced-order equations, and the data loss of the labeled reduced coefficients that are obtained via the projection of high-fidelity snapshots onto the reduced space. Such a network is referred to as physics-reinforced neural network (PRNN). As the number of residual points in time-parameter space can be very large, an accurate network \u2013 referred to as physics-informed neural network (PINN) \u2013 can be trained by minimizing only the residual loss. However, for complex nonlinear problems, the solution of the reduced-order equation is less accurate than the projection of high-fidelity solution onto the reduced space. Therefore, the PRNN trained with the snapshot data is expected to have higher accuracy than the PINN. Numerical results demonstrate that the PRNN is more accurate than the PINN and a purely data-driven neural network for complex problems. During the reduced basis refinement, the PRNN may obtain higher accuracy than the direct reduced-order model based on a Galerkin projection. The online evaluation of PINN/PRNN is orders of magnitude faster than that of the Galerkin reduced-order model. link Feb 23, 2022 Tommaso Tonolo Mean Field Analysis of Hypergraph Contagion Model, Desmond J. Higham and Henry-Louis de Kergorlay We typically interact in groups, not just in pairs. For this reason, it has recently been proposed that the spread of information, opinion or disease should be modelled over a hypergraph rather than a standard graph. The use of hyperedges naturally allows for a nonlinear rate of transmission, in terms of both the group size and the number of infected group members, as is the case, for example, when social distancing is encouraged. We consider a general class of individual-level, stochastic, susceptible-infected-susceptible models on a hypergraph, and focus on a mean field approximation proposed in [Arruda et al., Phys. Rev. Res., 2020]. We derive spectral conditions under which the mean field model predicts local or global stability of the infection-free state. We also compare these results with (a) a new condition that we derive for decay to zero in mean for the exact process, (b) conditions for a different mean field approximation in [Higham and de Kergorlay, Proc. Roy. Soc. A, 2021], and (c) numerical simulations of the microscale model. https://arxiv.org/abs/2108.05451 Feb 23, 2022 Arturo De Marinis Regularized nonlinear acceleration, by Damien Scieur, Alexandre d\u2019Aspremont, Francis Bach We describe a convergence acceleration technique for unconstrained optimization problems. Our scheme computes estimates of the optimum from a nonlinear average of the iterates produced by any optimization method. The weights in this average are computed via a simple linear system, whose solution can be updated online. This acceleration scheme runs in parallel to the base algorithm, providing improved estimates of the solution on the fly, while the original optimization method is running. Numerical experiments are detailed on classical classification problems. https://arxiv.org/abs/1606.04133 Feb 9, 2022 Konstantin Prokopchik Consensus Dynamics and Opinion Formation on Hypergraphs In this chapter, we derive and analyse models for consensus dynamics on hypergraphs. As we discuss, unless there are nonlinear node interaction functions, it is always possible to rewrite the system in terms of a new network of effective pairwise node interactions, regardless of the initially underlying multi-way interaction structure. We thus focus on dynamics based on a certain class of non-linear interaction functions, which can model different sociological phenomena such as peer pressure and stubbornness. Unlike for linear consensus dynamics on networks, we show how our nonlinear model dynamics can cause shifts away from the average system state. We examine how these shifts are influenced by the distribution of the initial states, the underlying hypergraph structure and different forms of non-linear scaling of the node interaction function. https://arxiv.org/abs/2105.01369 Jan 26, 2022 Simone Fioravanti EigenGame: PCA as Nash Equilibrium We present a novel view on principal component analysis (PCA) as a competitive game in which each approximate eigenvector is controlled by a player whose goal is to maximize their own utility function. We analyze the properties of this PCA game and the behavior of its gradient based updates. The resulting algorithm -- which combines elements from Oja's rule with a generalized Gram-Schmidt orthogonalization -- is naturally decentralized and hence parallelizable through message passing. We demonstrate the scalability of the algorithm with experiments on large image datasets and neural network activations. We discuss how this new view of PCA as a differentiable game can lead to further algorithmic developments and insights. ICLR 2021 - https://arxiv.org/abs/2010.00554 Dec 9, 2021 Dayana Savostianova Witches' Brew: Industrial Scale Data Poisoning via Gradient Matching Data Poisoning attacks modify training data to maliciously control a model trained on such data. In this work, we focus on targeted poisoning attacks which cause a reclassification of an unmodified test image and as such breach model integrity. We consider a particularly malicious poisoning attack that is both \"from scratch\" and \"clean label\", meaning we analyze an attack that successfully works against new, randomly initialized models, and is nearly imperceptible to humans, all while perturbing only a small fraction of the training data. Previous poisoning attacks against deep neural networks in this setting have been limited in scope and success, working only in simplified settings or being prohibitively expensive for large datasets. The central mechanism of the new attack is matching the gradient direction of malicious examples. We analyze why this works, supplement with practical considerations. and show its threat to real-world practitioners, finding that it is the first poisoning method to cause targeted misclassification in modern deep networks trained from scratch on a full-sized, poisoned ImageNet dataset. Finally we demonstrate the limitations of existing defensive strategies against such an attack, concluding that data poisoning is a credible threat, even for large-scale deep learning systems. ICLR 2021 - https://arxiv.org/abs/2009.02276 November 24, 2021","title":"COMPiLE Reading Group"},{"location":"research/","text":"Research & PhD Projects The research interests of the group include: Numerical integration of ODEs Numerical solution of nonlinear eigenvector problems Numerical linear algebra Computational machine learning and data science Spectral graph theory Numerical Optimization Analysis of complex networks and their applications to a wide range of real-world problems. Some specific topics of interest are described below. Efficient training of stable implicit-depth neural networks Supervised and semi-supervised classification are among the most important tasks in machine learning and data mining. The state-of-the-art techniques for both these two tasks are based on deep Neural Networks (NNs) or graph NNs. From a mathematical viewpoint, these models boil down to a regularized constrained optimization problem, $$\\begin{cases} \\min \\ell(f(x),y) + \\lambda \\varphi(f) & \\newline \\text{such that } f\\in \\mathcal F:=\\{f:f(x)=\\sigma(W_k\\sigma(\\cdots \\sigma(W_1\\sigma(W_0 x))\\cdots))\\} & \\end{cases}$$ where the constraints form a function space \\( \\mathcal F \\) parametrized by structured matrices \\(W = (W_0,\\dots,W_k)\\), including Toeplitz and multilevel Toeplitz matrices (convolutional operators) and graph or hypergraph matrices (discrete Laplacian operators and graph-convolutional filters). Recent work has shown the advantages of so-called implicit-depth or continuous-time neural networks, where the constraints in the NN optimization problem are defined via a nonlinear system of ODEs or PDEs, i.e. for instance we replace \\(f\\in \\mathcal F\\) with a differential equation of the form \\( \\dot f = f(W,t)\\). Popular instances of this type of NN models are so-called Neural ODE and Deep Equilibrium Models. These approaches, which trace back to early work on recurrent backpropagation, have a number of advantages: (a) they have been recently shown to match or even exceed the performance of traditional NNs on time series and image data (e.g. sequence modeling); (b) memory-wise, they are drastically more efficient than traditional NNs as backpropagation is done analytically and does not require to store internal weights, allowing to efficiently handle deeper architectures. While prediction accuracy of NN-based models has reached extraordinary performance, their potential instability with respect to adversarial attacks is a major limitation and one of the most important challenges in the field. Having guarantees of robustness against adversarial attacks is an essential requirement for the application of NNs in the society. In an unstable dynamical system, small perturbations of the initial state (the training dataset) may lead to very different solutions, thus a stable continuous-time NN architecture is an essential requirement for robustness against adversarial attacks. The obvious approach to ensure stability is to restrict the constraints set (the structure of the admissible functions), for example by limiting the matrix parameters to skew-Hermitian convolutional operators of the form $$ W = -BB^\\top,\\qquad W = \\begin{bmatrix} & B^\\top \\newline -B & \\end{bmatrix}\\, . $$ However, this approach further constrains the admissible functions set and reduces the applicability of the NN classifier and its classification performance. Leveraging recent techniques from matrix stability theory, we aim at developing new training algorithms for implicit-depth NN which will ensure forward (and, subsequently, backward) stability with the least reduction in terms of admissible constraint parameters. Methods from numerical ODEs and numerical linear algebra will be used to handle the differential nature of the problem and the large structured matrices involved as well as to prove the convergence of the training algorithm. Our numerical schemes will take advantage of the structure of convolutional operators and graph matrices to ensure efficiency in the training process and performance in terms of classification accuracy. Numerical integration of nonsmooth dynamical systems The numerical treatment of differential equations usually relies on smoothness assumptions which play a fundamental role in the development of suitable schemes and in their convergence analysis. However, an emergent field of interest is systems of ODEs with discontinuous right hand side and many applications can be found in control theory (bang-bang controls), mechanical systems (dry friction) biology (gene regulatory networks), chemistry (gas liquid models). In most mathematical models described by discontinuous ODEs the vector field is piecewise smooth in subregions separated by manifolds and discontinuities take place across the manifolds. The existence and uniqueness of solutions are not anymore guaranteed at such interfaces and the classical Filippov theory becomes ambiguous when the discontinuity manifolds have co-dimension greater than 1. Infinitely many vector fields could be selected along the discontinuity manifolds and the corresponding solutions might have different qualitative behavior. This issue clearly affects also the numerical approximation of the solutions. Our aim is to investigate physical regularizations so to allow one to select a Filippov solution that has physical relevance. If we can show that the solutions of the regularized system converge uniformly to a particular Filippov solution, then we can select this solution for the discontinuous problem. The persistence of the qualitative behavior of solutions under regularization is fundamental if we wish to replace the discontinuous system with the regular one or viceversa, hence we will investigate this persistence as well. At the state of the art, numerical techniques for discontinuous problems, even though efficient, need to select a priori a sliding vector field in Filippov convex combination. Our studies would give rigorous theoretical justifications to make such selection in agreement with the original real life model that one wishes to simulate. Our research project focuses on getting new theoretical insight into numerical approaches and on exploiting this insight for the design and implementation of efficient algorithms. Computational network science Networks are a very powerful tool to model complex systems and analyze large data. For example, in exploratory data analysis we are often interested in finding clusters or communities, or assessing the importance (or centrality) of datapoints. As many real-world systems feature geographical, temporal, or categorical metadata and higher-order structures (motifs), models based on higher-order graphs such as hypergraphs, multilayer graphs and simplicial complexes are nowadays becoming prevalent. We are interested in developing both theoretical foundations and efficient algorithms for a range of network analysis problems. We are particularly interested in methods that exploit matrix and tensor representations of the data to approximately solve related combinatorial optimization problems such as community detection, clustering, core-periphery analysis. Spectral methods for machine learning Spectral methods play a fundamental role in machine learning, statistics, and data mining. Methods for important tasks such as clustering, semi-supervised learning, dimensionality reduction, latent factor models, ranking and preference learning and covariance estimation all use information about eigenvalues and eigenvectors (or singular values and singular vectors) from an underlying data matrix. Even though spectral methods are both powerful and convenient, they often rely on a linear approximation of the ideal learning problem which sometimes yields inaccurate results. We are interested in developing spectral methods that are based on nonlinear eigenvalue problems with eigenvector nonlinearities. This class of eigenvector methods is very broad and includes several nonlinear dimensionality reduction models and tight relaxation of cut functions, to name some. Moreover, it allows us to develop numerical linear algebra tools to efficiently perform the nonlinear spectral methods.","title":"Research & PhD Projects"},{"location":"research/#research-phd-projects","text":"The research interests of the group include: Numerical integration of ODEs Numerical solution of nonlinear eigenvector problems Numerical linear algebra Computational machine learning and data science Spectral graph theory Numerical Optimization Analysis of complex networks and their applications to a wide range of real-world problems. Some specific topics of interest are described below.","title":"Research &amp; PhD Projects"},{"location":"research/#efficient-training-of-stable-implicit-depth-neural-networks","text":"Supervised and semi-supervised classification are among the most important tasks in machine learning and data mining. The state-of-the-art techniques for both these two tasks are based on deep Neural Networks (NNs) or graph NNs. From a mathematical viewpoint, these models boil down to a regularized constrained optimization problem, $$\\begin{cases} \\min \\ell(f(x),y) + \\lambda \\varphi(f) & \\newline \\text{such that } f\\in \\mathcal F:=\\{f:f(x)=\\sigma(W_k\\sigma(\\cdots \\sigma(W_1\\sigma(W_0 x))\\cdots))\\} & \\end{cases}$$ where the constraints form a function space \\( \\mathcal F \\) parametrized by structured matrices \\(W = (W_0,\\dots,W_k)\\), including Toeplitz and multilevel Toeplitz matrices (convolutional operators) and graph or hypergraph matrices (discrete Laplacian operators and graph-convolutional filters). Recent work has shown the advantages of so-called implicit-depth or continuous-time neural networks, where the constraints in the NN optimization problem are defined via a nonlinear system of ODEs or PDEs, i.e. for instance we replace \\(f\\in \\mathcal F\\) with a differential equation of the form \\( \\dot f = f(W,t)\\). Popular instances of this type of NN models are so-called Neural ODE and Deep Equilibrium Models. These approaches, which trace back to early work on recurrent backpropagation, have a number of advantages: (a) they have been recently shown to match or even exceed the performance of traditional NNs on time series and image data (e.g. sequence modeling); (b) memory-wise, they are drastically more efficient than traditional NNs as backpropagation is done analytically and does not require to store internal weights, allowing to efficiently handle deeper architectures. While prediction accuracy of NN-based models has reached extraordinary performance, their potential instability with respect to adversarial attacks is a major limitation and one of the most important challenges in the field. Having guarantees of robustness against adversarial attacks is an essential requirement for the application of NNs in the society. In an unstable dynamical system, small perturbations of the initial state (the training dataset) may lead to very different solutions, thus a stable continuous-time NN architecture is an essential requirement for robustness against adversarial attacks. The obvious approach to ensure stability is to restrict the constraints set (the structure of the admissible functions), for example by limiting the matrix parameters to skew-Hermitian convolutional operators of the form $$ W = -BB^\\top,\\qquad W = \\begin{bmatrix} & B^\\top \\newline -B & \\end{bmatrix}\\, . $$ However, this approach further constrains the admissible functions set and reduces the applicability of the NN classifier and its classification performance. Leveraging recent techniques from matrix stability theory, we aim at developing new training algorithms for implicit-depth NN which will ensure forward (and, subsequently, backward) stability with the least reduction in terms of admissible constraint parameters. Methods from numerical ODEs and numerical linear algebra will be used to handle the differential nature of the problem and the large structured matrices involved as well as to prove the convergence of the training algorithm. Our numerical schemes will take advantage of the structure of convolutional operators and graph matrices to ensure efficiency in the training process and performance in terms of classification accuracy.","title":"Efficient training of stable implicit-depth neural networks"},{"location":"research/#numerical-integration-of-nonsmooth-dynamical-systems","text":"The numerical treatment of differential equations usually relies on smoothness assumptions which play a fundamental role in the development of suitable schemes and in their convergence analysis. However, an emergent field of interest is systems of ODEs with discontinuous right hand side and many applications can be found in control theory (bang-bang controls), mechanical systems (dry friction) biology (gene regulatory networks), chemistry (gas liquid models). In most mathematical models described by discontinuous ODEs the vector field is piecewise smooth in subregions separated by manifolds and discontinuities take place across the manifolds. The existence and uniqueness of solutions are not anymore guaranteed at such interfaces and the classical Filippov theory becomes ambiguous when the discontinuity manifolds have co-dimension greater than 1. Infinitely many vector fields could be selected along the discontinuity manifolds and the corresponding solutions might have different qualitative behavior. This issue clearly affects also the numerical approximation of the solutions. Our aim is to investigate physical regularizations so to allow one to select a Filippov solution that has physical relevance. If we can show that the solutions of the regularized system converge uniformly to a particular Filippov solution, then we can select this solution for the discontinuous problem. The persistence of the qualitative behavior of solutions under regularization is fundamental if we wish to replace the discontinuous system with the regular one or viceversa, hence we will investigate this persistence as well. At the state of the art, numerical techniques for discontinuous problems, even though efficient, need to select a priori a sliding vector field in Filippov convex combination. Our studies would give rigorous theoretical justifications to make such selection in agreement with the original real life model that one wishes to simulate. Our research project focuses on getting new theoretical insight into numerical approaches and on exploiting this insight for the design and implementation of efficient algorithms.","title":"Numerical integration of nonsmooth dynamical systems"},{"location":"research/#computational-network-science","text":"Networks are a very powerful tool to model complex systems and analyze large data. For example, in exploratory data analysis we are often interested in finding clusters or communities, or assessing the importance (or centrality) of datapoints. As many real-world systems feature geographical, temporal, or categorical metadata and higher-order structures (motifs), models based on higher-order graphs such as hypergraphs, multilayer graphs and simplicial complexes are nowadays becoming prevalent. We are interested in developing both theoretical foundations and efficient algorithms for a range of network analysis problems. We are particularly interested in methods that exploit matrix and tensor representations of the data to approximately solve related combinatorial optimization problems such as community detection, clustering, core-periphery analysis.","title":"Computational network science"},{"location":"research/#spectral-methods-for-machine-learning","text":"Spectral methods play a fundamental role in machine learning, statistics, and data mining. Methods for important tasks such as clustering, semi-supervised learning, dimensionality reduction, latent factor models, ranking and preference learning and covariance estimation all use information about eigenvalues and eigenvectors (or singular values and singular vectors) from an underlying data matrix. Even though spectral methods are both powerful and convenient, they often rely on a linear approximation of the ideal learning problem which sometimes yields inaccurate results. We are interested in developing spectral methods that are based on nonlinear eigenvalue problems with eigenvector nonlinearities. This class of eigenvector methods is very broad and includes several nonlinear dimensionality reduction models and tight relaxation of cut functions, to name some. Moreover, it allows us to develop numerical linear algebra tools to efficiently perform the nonlinear spectral methods.","title":"Spectral methods for machine learning"},{"location":"seminar/","text":"NOMADS Seminar We organize a seminar in Numerical ODEs, Matrix Analysis and Data Science. The seminar is scheduled on Wednesdays at 17:00 (CET). The seminar focuses on various topics in numerical analysis, numerical linear algebra, scientific computing and matrix theory with particular emphasis on their application in control theory, network science, data mining and machine learning. Questions or comments about the seminar should be sent to Nicola Guglielmi or Francesco Tudisco . Speaker Title, Abstract & Other Info Date Stefano Serra-Capizzano University of Insubria, Italy TBA May 26, 2022 Paolo Cifani Gran Sasso Science Institute, Italy Geometric integration of Lie-Poisson flows on the sphere In this seminar I will touch upon the recent developments in structure-preserving (geometric) integration of Euler\u2019s equations for two-dimensional incompressible flows. It has been known for half a century that the dynamics of incompressible ideal fluids in two dimensions can be understood as an evolution equation on the contangent bundle of the infinite-dimensional Lie group of symplectic dffeomorphisms. In particular, the vorticity equation constitutes a Lie-Poisson system characterized by an infinite number of first integrals, i.e. the integrated powers of vorticity. This set of constraints, absent in three dimensions, has profound effects on the energy transfer mechanisms across scales of motion. Yet, the construction of a numerical system which preserves this rich Poisson structure has been elusive. Most attempts either fail in fully preserving the geometric structure or have a high computational complexity. Here, I will show that, thanks to our recent advances, it possible to design a geometric integrator which embeds this fundamental principle of the continuum into the discrete system at a modest computational cost. The construction of such scheme, the main numerical algorithms and their parallelisation on modern supercomputing facilities will be discussed. Finally, an application to the spectrum of homogeneous two-dimensional turbulence will be illustrated. May 24, 2022 Simone Camarri University of Pisa, Italy TBA May 18, 2022 Ernst Hairer University of Geneva, Switzerland High order PDE-convergence of ADI-type integrators for parabolic problems This work considers space-discretised parabolic problems on a rectangular domain subject to Dirichlet boundary conditions. For the time integration s-stage AMF-W-methods, which are ADI (Alternating Direction Implicit) type integrators, are considered. They are particularly efficient when the space dimension of the problem is large. The classical algebraic conditions for order p (with p<=3) are shown to be sufficient for PDE-convergence of order p (independently of the spatial resolution) in the case of time independent Dirichlet boundary conditions. Under additional conditions, PDE-convergence of order p=3.25-eps for every eps>0 can be obtained. In the case of time dependent boundary conditions there is an order reduction. This is joint work with Severiano Gonzalez-Pinto and Domingo Hernandez-Abreu. Related publications can be downloaded from http://www.unige.ch/~hairer/preprints.html April 26, 2022 Marino Zennaro University of Trieste, Italy Computing antinorms on multicones Abstract March 31, 2022 Giorgio Fusco University of L'Aquila, Italy TBA Feb 24, 2022 Erkki Somersalo Case Western Reserve University, USA Bayes meets data science to identify changes in brain activity during meditation from MEG measurements Meditation as a potential alternative for pharmaceutical intervention to mitigate conditions such as chronic pain or clinical depression continues to obtain significant attention. One of the problems is that often the positive effects of meditation that have been reported are anecdotal or are based on self reporting. To quantify the effects of meditation, it is therefore important to develop methods based on medical imaging to identify brain regions that are involved in the meditation practice. In this talk, we review some recent results about this topic, addressed by using magnetoencephalography (MEG) to map brain activity during meditation. One of the difficulties here is that the data are less sensitive to activity taking place in the deep brain regions, including the limbic system that is believed to play an important role in meditation. The MEG inverse problem is addressed by using novel Bayesian methods combined with advanced numerical techniques, applied on data from professional Buddhist meditators. The reconstructed activity is then analyzed using data science techniques to distill the information about the activation changes during meditation. Recording of the talk (available to GSSI only) December 17, 2021 Matthew Colbrook University of Cambridge, UK Computing semigroups and time-fractional PDEs with error control We develop an algorithm that computes strongly continuous semigroups on infinite-dimensional Hilbert spaces with explicit error control. Given a generator $A$, a time $t > 0$, an arbitrary initial vector $u_0$ and an error tolerance $\\epsilon > 0$, the algorithm computes $\\exp(tA)u_0$ with error bounded by $\\epsilon$. The (parallelisable) algorithm is based on a combination of a regularized functional calculus, suitable contour quadrature rules and the adaptive computation of resolvents in infinite dimensions. As a particular case, we deal with semigroups on $L^2(R^d)$ that are generated by partial differential operators with polynomially bounded coefficients of locally bounded total variation. For analytic semigroups, we provide a quadrature rule whose error decreases like $\\exp(\u2212cN/ log(N))$ for $N$ quadrature points, that remains stable as $N \\to \\infty$, and which is also suitable for infinite-dimensional operators. Finally, we extend the method to time-fractional PDEs (where it avoids singularities as $t \\to 0$ and large memory consumption). Numerical examples are given, including: Schr\u00f6dinger and wave equations on the aperiodic Ammann\u2013Beenker tiling and fractional beam equations arising in the modelling of small-amplitude vibration of viscoelastic materials. The spectral analysis (which is always needed for contour methods) is considerably simplified due to an infinite-dimensional \u201csolve-then-discretise\u201d approach. December 1, 2021 Speaker Title, Abstract & Other Info Date Lars Ruthotto Emory University, USA Numerical Methods for Deep Learning motivated by Partial Differential Equations Understanding the world through data and computation has always formed the core of scientific discovery. Amid many different approaches, two common paradigms have emerged. On the one hand, primarily data-driven approaches\u2014such as deep neural networks\u2014have proven extremely successful in recent years. Their success is based mainly on their ability to approximate complicated functions with generic models when trained using vast amounts of data and enormous computational resources. But despite many recent triumphs, deep neural networks are difficult to analyze and thus remain mysterious. Most importantly, they lack the robustness, explainability, interpretability, efficiency, and fairness needed for high-stakes decision-making. On the other hand, increasingly realistic model-based approaches\u2014typically derived from first principles and formulated as partial differential equations (PDEs)\u2014are now available for various tasks. One can often calibrate these models\u2014which enable detailed theoretical studies, analysis, and interpretation\u2014with relatively few measurements, thus facilitating their accurate predictions of phenomena. In this talk, I will highlight recent advances and ongoing work to understand and improve deep learning by using techniques from partial differential equations. I will demonstrate how PDE techniques can yield better insight into deep learning algorithms, more robust networks, and more efficient numerical algorithms. I will also expose some of the remaining computational and numerical challenges in this area. Slides of the talk Recording of the talk (available to GSSI only) June 17, 2021 Ivan Markovsky Vrije Universiteit Brussel, Belgium Data-driven dynamic interpolation and approximation The behavioral system theory give theoretical foundation for nonparameteric representations of linear time-invariant systems based on Hankel matrices constructed from data. These data-driven representations led in turn to new system identification, signal processing, and control methods. In particular, data-driven simulation and linear quadratic tracking control problems were solved using the new approach [1,2]. This talk shows how the approach can be used further on for solving data-driven interpolation and approximation problems (missing data estimation) and how it can be generalized to some classes of nonlinear systems. The theory leads to algorithms that are both general (can deal simultaneously with missing, exact, and noisy data of multivariable systems) and simple (require existing numerical linear algebra methods only). This opens a practical computational way of doing system theory and signal processing directly from data without identification of a transfer function or a state space representation and doing model-based design. References: [1] I. Markovsky and P. Rapisarda. \u201cData-driven simulation and control\u201d. Int. J. Control 81.12 (2008), pp. 1946--1959. [2] I. Markovsky. A missing data approach to data-driven filtering and control. IEEE Trans. Automat. Contr., 62:1972--1978, April 2017. [3] I. Markovsky and F. D\u00f6rfler. Data-driven dynamic interpolation and approximation. Technical report, Vrije Universiteit Brussel, 2021. Available from Ivan's webpage Zoom link Add event to Google calendar Recording of the talk (available to GSSI only) March 30, 2021 Eugene E. Tyrtyshnikov Institute for Numerical Mathematics, Russian Academy of Sciences Tikhonov's solution to a class of linear systems equivalent within perturbations A standard approach to incorrect problems suggests that a problem of interest is reformulated with the knowledge of some additional a-priori information. This can be done by several well-known regularization techniques. Many practical problems are successfully solved on this way. What does not still look as completely satisfactory is that the new reset problem seems to appear rather implicitly in the very process of its solution. In 1980, A. N. Tikhonov proposed a reformulation [1] that arises explicitly before the discussion of the solution methods. He suggested a notion of normal solution to a family of linear algebraic systems described by a given individual system and its vicinity comprising perturbed systems, under the assumption that there are compatible systems in the class notwithstanding the compatibility property of the given individual system. Tikhovov proved that the normal solution exists and is unique. However, a natural question about the correctness of the reset problem was not answered. In this talk we address a question of correctness of the reformulated incorrect problems that seems to have been missed in all previous considerations. The main result is the proof of correctness for Tikhonov's normal solution. Possible generalizations and difficulties will be also discussed. [1] A. N. Tikhonov, Approximate systems of linear algebraic equations, USSR Computational Mathematics and Mathematical Physics, vol. 20, issue 6 (1980) Zoom link Add event to Google calendar March 09, 2021 Michael Schaub RWTH Aachen University Learning from signals on graphs with unobserved edges In many applications we are confronted with the following system identification scenario: we observe a dynamical process that describes the state of a system at particular times. Based on these observations we want to infer the (dynamical) interactions between the entities we observe. In the context of a distributed system, this typically corresponds to a \"network identification\" task: find the (weighted) edges of the graph of interconnections. However, often the number of samples we can obtain from such a process are far too few to identify the edges of the network exactly. Can we still reliably infer some aspects of the underlying system? Motivated by this question we consider the following identification problem: instead of trying to infer the exact network, we aim to recover a (low-dimensional) statistical model of the network based on the observed signals on the nodes. More concretely, here we focus on observations that consist of snapshots of a diffusive process that evolves over the unknown network. We model the (unobserved) network as generated from an independent draw from a latent stochastic blockmodel (SBM), and our goal is to infer both the partition of the nodes into blocks, as well as the parameters of this SBM. We present simple spectral algorithms that provably solve the partition and parameter inference problems with high-accuracy. We further discuss some possible variations and extensions of this problem setup. Zoom link Add event to Google calendar Recording of the talk February 17, 2021 Lothar Reichel Kent State University Large-scale regression with non-convex loss and penalty We do non-convex optimization with application to image restoration and regression problems for which a sparse solution is desired. Zoom link Add event to Google calendar February 4, 2021 Anders Hansen University of Cambridge, UK On the foundations of computational mathematics, Smale's 18th problem and the potential limits of AI There is a profound optimism on the impact of deep learning (DL) and AI in the sciences with Geoffrey Hinton concluding that 'They should stop training radiologists now'. However, DL has an Achilles heel: it is universaly unstable so that small changes in the initial data can lead to large errors in the final result. This has been documented in a wide variety of applications. Paradoxically, the existence of stable neural networks for these applications is guaranteed by the celebrated Universal Approximation Theorem, however, the stable neural networks are never computed by the current training approaches. We will address this problem and the potential limitations of AI from a foundations point of view. Indeed, the current situation in AI is comparable to the situation in mathematics in the early 20th century, when David Hilbert\u2019s optimism (typically reflected in his 10th problem) suggested no limitations to what mathematics could prove and no restrictions on what computers could compute. Hilbert\u2019s optimism was turned upside down by Goedel and Turing, who established limitations on what mathematics can prove and which problems computers can solve (however, without limiting the impact of mathematics and computer science). We predict a similar outcome for modern AI and DL, where the limitations of AI (the main topic of Smale\u2019s 18th problem) will be established through the foundations of computational mathematics. We sketch the beginning of such a program by demonstrating how there exist neural networks approximating classical mappings in scientific computing, however, no algorithm (even randomised) can compute such a network to even 1-digit accuracy (with probability better than 1/2). We will also show how instability is inherit in the methodology of DL demonstrating that there is no easy remedy, given the current methodology. Finally, we will demonstrate basic examples in inverse problems where there exists (untrained) neural networks that can easily compute a solution to the problem, however, the current DL techniques will need 10^80 data points in the training set to get even 1% success rate. Recording of the talk January 28, 2021 Gianluca Ceruti University of Tuebingen Numerical integrators for dynamical low-rank approximation Discretization of time-dependent high-dimensional PDEs suffers of an undesired effect, known as curse of dimensionality. The amount of data to be stored and treated, grows exponentially, and exceeds standard capacity of common computational devices. In this setting, time dependent model order reductions techniques are desirable. In the present seminar, together with efficient numerical integrators, we present a recently developed approach: dynamical low-rank approximation. Dynamical low-rank approximation for matrices will be firstly presented, and a numerical integrator with two remarkable properties will be introduced: the matrix projector splitting integrator. Based upon this numerical integrator, we will construct two equivalent extensions for tensors, multi-dimensional arrays, in Tucker format - a high-order generalization of the SVD decomposition for matrices. These extensions are proven to preserve the excellent qualities of the matrix integrator. To conclude, via a novel compact formulation of the Tucker integrator, we will further extend the matrix and Tucker projector splitting integrators to the most general class of Tree Tensor Networks. Important examples belonging to this class and of interest for applications are given, but not only restricted to, by Tensor Trains. This seminar is based upon a joint work with Ch. Lubich and H. Walach. Zoom link Add event to Google calendar January 13, 2021 Alexander Viguerie GSSI Efficient, stable, and reliable solvers for the Steady Incompressible Navier-Stokes equations: application to Computational Hemodynamics. Over the past several years, computational fluid dynamics (CFD) simulations have become increasingly popular as a clinical tool for cardiologists at the patient-specific level. The use of CFD in this area poses several challenges. The clinical setting places heavy restrictions on both computational time and power. Simulation results are usually desired within minutes and are usually run on standard computers. For these reasons, steady-state Navier-Stokes simulations are usually preferred, as they can be completed in a fraction of the time required to run an unsteady computation. However, in many respects the steady problem is more difficult than the unsteady one, particularly in regards to solving the associated linear and nonlinear systems. Additionally, boundary data for patient-specific problems is often missing, incomplete, or unreliable. This makes the determination of a useful model challenging, as it requires the generation of reliable boundary data without introducing heavy computational costs. This seminar will address these challenges, as well as some others, and introduce new techniques for workarounds. Results from patient-specific cases will be presented and discussed. Recording of the talk (available to GSSI only) Zoom link Add event to Google calendar December 16, 2020 Martin Stoll TU-Chemnitz From PDEs to data science: an adventure with the graph Laplacian In this talk we briefly review some basic PDE models that are used to model phase separation in materials science. They have since become important tools in image processing and over the last years semi-supervised learning strategies could be implemented with these PDEs at the core. The main ingredient is the graph Laplacian that stems from a graph representation of the data. This matrix is large and typically dense. We illustrate some of its crucial features and show how to efficiently work with the graph Laplacian. In particular, we need some of its eigenvectors and for this the Lanczos process needs to be implemented efficiently. Here, we suggest the use of the NFFT method for evaluating the matrix vector products without even fully constructing the matrix. We illustrate the performance on several examples. Recording of the talk (available to GSSI only) Zoom link Add event to Google calendar December 2, 2020 Patricia Diaz De Alba GSSI Numerical treatment for inverse electromagnetic problems Electromagnetic induction surveys are among the most popular techniques for non-destructive investigation of soil properties, in order to detect the presence of both ground inhomogeneities and particular substances. Frequency-domain electromagnetic instruments allow the collection of data in different configurations, that is, varying the intercoil spacing, the frequency, and the height above the ground. Based on a non-linear forward model used to describe the interaction between an electromagnetic field and the soil, the aim is to reconstruct the distribution of either the electrical conductivity or the magnetic permeability with respect to depth. To this end, the inversion of both the real (in-phase) and the imaginary (quadrature) components of the signal are studied by a regularized damped Gauss-Newton method. The regularization part of the algorithm is based on a low-rank approximation of the Jacobian of the non-linear model. Furthermore, in many situations, a regularization scheme retrieving smooth solutions is blindly applied, without taking into account the prior available knowledge. An algorithm for a regularization method that promotes the sparsity of the reconstructed electrical conductivity or magnetic permeability distribution is available. This regularization strategy incorporates a minimum gradient support stabilizer into a truncated generalized singular value decomposition scheme. The whole inversion algorithm has been enclosed in a MATLAB package, called FDEMtools, allowing the user to experiment with synthetic and experimental data sets, and different regularization strategies, in order to compare them and draw conclusions. The numerical effectiveness of the inversion procedure is demonstrated on synthetic and real datasets by using FDEMtools package. Zoom link Add event to Google calendar November 20, 2020 Christian Lubich University of Tuebingen Dynamical low-rank approximation This talk reviews differential equations and their numerical solution on manifolds of low-rank matrices or of tensors with a rank structure such as tensor trains or general tree tensor networks. These low-rank differential equations serve to approximate, in a data-compressed format, large time-dependent matrices and tensors or multivariate functions that are either given explicitly via their increments or are unknown solutions to high-dimensional evolutionary differential equations, with multi-particle time-dependent Schr\u00f6dinger equations and kinetic equations such as Vlasov equations as noteworthy examples of applications. Recently developed numerical time integrators are based on splitting the projection onto the tangent space of the low-rank manifold at the current approximation. In contrast to all standard integrators, these projector-splitting methods are robust to the unavoidable presence of small singular values in the low-rank approximation. This robustness relies on exploiting geometric properties of the manifold of low-rank matrices or tensors: in each substep of the projector-splitting algorithm, the approximation moves along a flat subspace of the low-rank manifold. In this way, high curvature due to small singular values does no harm. This talk is based on work done intermittently over the last decade with Othmar Koch, Bart Vandereycken, Ivan Oseledets, Emil Kieri, Hanna Walach and Gianluca Ceruti. Zoom link Add event to Google calendar November 18, 2020 Raffaele D'Ambrosio University of L'Aquila Structure-preserving numerics for stochastic differential equations Modern Numerical Analysis is not only devoted to accurately approximating the solutions of various problems through efficient and robust schemes, but also to retaining qualitative properties of the continuous problem over long times. Sometimes such conservation properties naturally characterize the numerical schemes, while in more complex situations preservation issues have to be conveyed into the numerical approximations. The talk is focused on presenting recent advances in structure-preservation issues for selected stochastic differential equations satisfying some characteristic invariance laws. The behaviour of stochastic multistep methods in the preservation of mean-square contractivity will be analyzed; we show, in this case, that conservation properties are hidden, as a matter of fact, into conditional stability properties of numerical schemes. The analysis will also be conveyed to the discretization of stochastic Hamiltonian problems for the numerical preservation of the behaviour of the expected Hamiltonian. The theoretical analysis will also be supported by the numerical evidence. Zoom link Add event to Google calendar November 4, 2020 Giacomo Baggio University of Padua From Model-Based to Data-Driven Control of Network Dynamics The control of complex dynamical networks has attracted increasing interest over the past few years, with reference, in particular, to problems of controllability, optimal input design, and minimal actuator placement. In this talk, I will address the problem of controlling linear dynamical networks from a control-energy or \"practical\" perspective. I will first focus on the model-based scenario and review the fundamental metrics, theoretical limitations, and challenges in controlling networks using a limited number of control nodes. In particular, I will emphasize the impact of the \"degree\" of non-normality of the network's adjacency matrix on the control performance. Then, I will switch to a data-driven scenario, and show how some network control problems can be efficiently solved by relying on experimental data only. Slides of the seminar Zoom link Add event to Google calendar October 14, 2020 Federico Poloni University of Pisa Inverses of quasidefinite matrices in block-factored form, with an application to control theory (joint work with P. Benner) We describe an algorithm to compute the explicit inverse of a dense quasi-definite matrix, i.e., a symmetric matrix of the form [-BB^T, A; A^T, C^TC], with the (1,1) block negative semidefinite and the (2,2) block positive semidefinite. The algorithm is a variant of Gauss-Jordan elimination that works on the low-rank factors $B$ and $C$ directly without ever forming those blocks. The individual elimination steps amount to a transformation called principal pivot transform ; it was shown in [Poloni, Strabic 2016] how to perform it by working only on $A, B, C$, and we rely on that procedure here. We discuss the stability of the resulting method, and show how the algorithm (and in particular the produced low-rank factors) can be of use in control theory, in the context of the matrix sign iteration, which is a method used to solve algebraic Riccati equations. Zoom link Add event to Google calendar September 30, 2020","title":"Seminar"},{"location":"seminar/#nomads-seminar","text":"We organize a seminar in Numerical ODEs, Matrix Analysis and Data Science. The seminar is scheduled on Wednesdays at 17:00 (CET). The seminar focuses on various topics in numerical analysis, numerical linear algebra, scientific computing and matrix theory with particular emphasis on their application in control theory, network science, data mining and machine learning. Questions or comments about the seminar should be sent to Nicola Guglielmi or Francesco Tudisco . Speaker Title, Abstract & Other Info Date Stefano Serra-Capizzano University of Insubria, Italy TBA May 26, 2022 Paolo Cifani Gran Sasso Science Institute, Italy Geometric integration of Lie-Poisson flows on the sphere In this seminar I will touch upon the recent developments in structure-preserving (geometric) integration of Euler\u2019s equations for two-dimensional incompressible flows. It has been known for half a century that the dynamics of incompressible ideal fluids in two dimensions can be understood as an evolution equation on the contangent bundle of the infinite-dimensional Lie group of symplectic dffeomorphisms. In particular, the vorticity equation constitutes a Lie-Poisson system characterized by an infinite number of first integrals, i.e. the integrated powers of vorticity. This set of constraints, absent in three dimensions, has profound effects on the energy transfer mechanisms across scales of motion. Yet, the construction of a numerical system which preserves this rich Poisson structure has been elusive. Most attempts either fail in fully preserving the geometric structure or have a high computational complexity. Here, I will show that, thanks to our recent advances, it possible to design a geometric integrator which embeds this fundamental principle of the continuum into the discrete system at a modest computational cost. The construction of such scheme, the main numerical algorithms and their parallelisation on modern supercomputing facilities will be discussed. Finally, an application to the spectrum of homogeneous two-dimensional turbulence will be illustrated. May 24, 2022 Simone Camarri University of Pisa, Italy TBA May 18, 2022 Ernst Hairer University of Geneva, Switzerland High order PDE-convergence of ADI-type integrators for parabolic problems This work considers space-discretised parabolic problems on a rectangular domain subject to Dirichlet boundary conditions. For the time integration s-stage AMF-W-methods, which are ADI (Alternating Direction Implicit) type integrators, are considered. They are particularly efficient when the space dimension of the problem is large. The classical algebraic conditions for order p (with p<=3) are shown to be sufficient for PDE-convergence of order p (independently of the spatial resolution) in the case of time independent Dirichlet boundary conditions. Under additional conditions, PDE-convergence of order p=3.25-eps for every eps>0 can be obtained. In the case of time dependent boundary conditions there is an order reduction. This is joint work with Severiano Gonzalez-Pinto and Domingo Hernandez-Abreu. Related publications can be downloaded from http://www.unige.ch/~hairer/preprints.html April 26, 2022 Marino Zennaro University of Trieste, Italy Computing antinorms on multicones Abstract March 31, 2022 Giorgio Fusco University of L'Aquila, Italy TBA Feb 24, 2022 Erkki Somersalo Case Western Reserve University, USA Bayes meets data science to identify changes in brain activity during meditation from MEG measurements Meditation as a potential alternative for pharmaceutical intervention to mitigate conditions such as chronic pain or clinical depression continues to obtain significant attention. One of the problems is that often the positive effects of meditation that have been reported are anecdotal or are based on self reporting. To quantify the effects of meditation, it is therefore important to develop methods based on medical imaging to identify brain regions that are involved in the meditation practice. In this talk, we review some recent results about this topic, addressed by using magnetoencephalography (MEG) to map brain activity during meditation. One of the difficulties here is that the data are less sensitive to activity taking place in the deep brain regions, including the limbic system that is believed to play an important role in meditation. The MEG inverse problem is addressed by using novel Bayesian methods combined with advanced numerical techniques, applied on data from professional Buddhist meditators. The reconstructed activity is then analyzed using data science techniques to distill the information about the activation changes during meditation. Recording of the talk (available to GSSI only) December 17, 2021 Matthew Colbrook University of Cambridge, UK Computing semigroups and time-fractional PDEs with error control We develop an algorithm that computes strongly continuous semigroups on infinite-dimensional Hilbert spaces with explicit error control. Given a generator $A$, a time $t > 0$, an arbitrary initial vector $u_0$ and an error tolerance $\\epsilon > 0$, the algorithm computes $\\exp(tA)u_0$ with error bounded by $\\epsilon$. The (parallelisable) algorithm is based on a combination of a regularized functional calculus, suitable contour quadrature rules and the adaptive computation of resolvents in infinite dimensions. As a particular case, we deal with semigroups on $L^2(R^d)$ that are generated by partial differential operators with polynomially bounded coefficients of locally bounded total variation. For analytic semigroups, we provide a quadrature rule whose error decreases like $\\exp(\u2212cN/ log(N))$ for $N$ quadrature points, that remains stable as $N \\to \\infty$, and which is also suitable for infinite-dimensional operators. Finally, we extend the method to time-fractional PDEs (where it avoids singularities as $t \\to 0$ and large memory consumption). Numerical examples are given, including: Schr\u00f6dinger and wave equations on the aperiodic Ammann\u2013Beenker tiling and fractional beam equations arising in the modelling of small-amplitude vibration of viscoelastic materials. The spectral analysis (which is always needed for contour methods) is considerably simplified due to an infinite-dimensional \u201csolve-then-discretise\u201d approach. December 1, 2021 Speaker Title, Abstract & Other Info Date Lars Ruthotto Emory University, USA Numerical Methods for Deep Learning motivated by Partial Differential Equations Understanding the world through data and computation has always formed the core of scientific discovery. Amid many different approaches, two common paradigms have emerged. On the one hand, primarily data-driven approaches\u2014such as deep neural networks\u2014have proven extremely successful in recent years. Their success is based mainly on their ability to approximate complicated functions with generic models when trained using vast amounts of data and enormous computational resources. But despite many recent triumphs, deep neural networks are difficult to analyze and thus remain mysterious. Most importantly, they lack the robustness, explainability, interpretability, efficiency, and fairness needed for high-stakes decision-making. On the other hand, increasingly realistic model-based approaches\u2014typically derived from first principles and formulated as partial differential equations (PDEs)\u2014are now available for various tasks. One can often calibrate these models\u2014which enable detailed theoretical studies, analysis, and interpretation\u2014with relatively few measurements, thus facilitating their accurate predictions of phenomena. In this talk, I will highlight recent advances and ongoing work to understand and improve deep learning by using techniques from partial differential equations. I will demonstrate how PDE techniques can yield better insight into deep learning algorithms, more robust networks, and more efficient numerical algorithms. I will also expose some of the remaining computational and numerical challenges in this area. Slides of the talk Recording of the talk (available to GSSI only) June 17, 2021 Ivan Markovsky Vrije Universiteit Brussel, Belgium Data-driven dynamic interpolation and approximation The behavioral system theory give theoretical foundation for nonparameteric representations of linear time-invariant systems based on Hankel matrices constructed from data. These data-driven representations led in turn to new system identification, signal processing, and control methods. In particular, data-driven simulation and linear quadratic tracking control problems were solved using the new approach [1,2]. This talk shows how the approach can be used further on for solving data-driven interpolation and approximation problems (missing data estimation) and how it can be generalized to some classes of nonlinear systems. The theory leads to algorithms that are both general (can deal simultaneously with missing, exact, and noisy data of multivariable systems) and simple (require existing numerical linear algebra methods only). This opens a practical computational way of doing system theory and signal processing directly from data without identification of a transfer function or a state space representation and doing model-based design. References: [1] I. Markovsky and P. Rapisarda. \u201cData-driven simulation and control\u201d. Int. J. Control 81.12 (2008), pp. 1946--1959. [2] I. Markovsky. A missing data approach to data-driven filtering and control. IEEE Trans. Automat. Contr., 62:1972--1978, April 2017. [3] I. Markovsky and F. D\u00f6rfler. Data-driven dynamic interpolation and approximation. Technical report, Vrije Universiteit Brussel, 2021. Available from Ivan's webpage Zoom link Add event to Google calendar Recording of the talk (available to GSSI only) March 30, 2021 Eugene E. Tyrtyshnikov Institute for Numerical Mathematics, Russian Academy of Sciences Tikhonov's solution to a class of linear systems equivalent within perturbations A standard approach to incorrect problems suggests that a problem of interest is reformulated with the knowledge of some additional a-priori information. This can be done by several well-known regularization techniques. Many practical problems are successfully solved on this way. What does not still look as completely satisfactory is that the new reset problem seems to appear rather implicitly in the very process of its solution. In 1980, A. N. Tikhonov proposed a reformulation [1] that arises explicitly before the discussion of the solution methods. He suggested a notion of normal solution to a family of linear algebraic systems described by a given individual system and its vicinity comprising perturbed systems, under the assumption that there are compatible systems in the class notwithstanding the compatibility property of the given individual system. Tikhovov proved that the normal solution exists and is unique. However, a natural question about the correctness of the reset problem was not answered. In this talk we address a question of correctness of the reformulated incorrect problems that seems to have been missed in all previous considerations. The main result is the proof of correctness for Tikhonov's normal solution. Possible generalizations and difficulties will be also discussed. [1] A. N. Tikhonov, Approximate systems of linear algebraic equations, USSR Computational Mathematics and Mathematical Physics, vol. 20, issue 6 (1980) Zoom link Add event to Google calendar March 09, 2021 Michael Schaub RWTH Aachen University Learning from signals on graphs with unobserved edges In many applications we are confronted with the following system identification scenario: we observe a dynamical process that describes the state of a system at particular times. Based on these observations we want to infer the (dynamical) interactions between the entities we observe. In the context of a distributed system, this typically corresponds to a \"network identification\" task: find the (weighted) edges of the graph of interconnections. However, often the number of samples we can obtain from such a process are far too few to identify the edges of the network exactly. Can we still reliably infer some aspects of the underlying system? Motivated by this question we consider the following identification problem: instead of trying to infer the exact network, we aim to recover a (low-dimensional) statistical model of the network based on the observed signals on the nodes. More concretely, here we focus on observations that consist of snapshots of a diffusive process that evolves over the unknown network. We model the (unobserved) network as generated from an independent draw from a latent stochastic blockmodel (SBM), and our goal is to infer both the partition of the nodes into blocks, as well as the parameters of this SBM. We present simple spectral algorithms that provably solve the partition and parameter inference problems with high-accuracy. We further discuss some possible variations and extensions of this problem setup. Zoom link Add event to Google calendar Recording of the talk February 17, 2021 Lothar Reichel Kent State University Large-scale regression with non-convex loss and penalty We do non-convex optimization with application to image restoration and regression problems for which a sparse solution is desired. Zoom link Add event to Google calendar February 4, 2021 Anders Hansen University of Cambridge, UK On the foundations of computational mathematics, Smale's 18th problem and the potential limits of AI There is a profound optimism on the impact of deep learning (DL) and AI in the sciences with Geoffrey Hinton concluding that 'They should stop training radiologists now'. However, DL has an Achilles heel: it is universaly unstable so that small changes in the initial data can lead to large errors in the final result. This has been documented in a wide variety of applications. Paradoxically, the existence of stable neural networks for these applications is guaranteed by the celebrated Universal Approximation Theorem, however, the stable neural networks are never computed by the current training approaches. We will address this problem and the potential limitations of AI from a foundations point of view. Indeed, the current situation in AI is comparable to the situation in mathematics in the early 20th century, when David Hilbert\u2019s optimism (typically reflected in his 10th problem) suggested no limitations to what mathematics could prove and no restrictions on what computers could compute. Hilbert\u2019s optimism was turned upside down by Goedel and Turing, who established limitations on what mathematics can prove and which problems computers can solve (however, without limiting the impact of mathematics and computer science). We predict a similar outcome for modern AI and DL, where the limitations of AI (the main topic of Smale\u2019s 18th problem) will be established through the foundations of computational mathematics. We sketch the beginning of such a program by demonstrating how there exist neural networks approximating classical mappings in scientific computing, however, no algorithm (even randomised) can compute such a network to even 1-digit accuracy (with probability better than 1/2). We will also show how instability is inherit in the methodology of DL demonstrating that there is no easy remedy, given the current methodology. Finally, we will demonstrate basic examples in inverse problems where there exists (untrained) neural networks that can easily compute a solution to the problem, however, the current DL techniques will need 10^80 data points in the training set to get even 1% success rate. Recording of the talk January 28, 2021 Gianluca Ceruti University of Tuebingen Numerical integrators for dynamical low-rank approximation Discretization of time-dependent high-dimensional PDEs suffers of an undesired effect, known as curse of dimensionality. The amount of data to be stored and treated, grows exponentially, and exceeds standard capacity of common computational devices. In this setting, time dependent model order reductions techniques are desirable. In the present seminar, together with efficient numerical integrators, we present a recently developed approach: dynamical low-rank approximation. Dynamical low-rank approximation for matrices will be firstly presented, and a numerical integrator with two remarkable properties will be introduced: the matrix projector splitting integrator. Based upon this numerical integrator, we will construct two equivalent extensions for tensors, multi-dimensional arrays, in Tucker format - a high-order generalization of the SVD decomposition for matrices. These extensions are proven to preserve the excellent qualities of the matrix integrator. To conclude, via a novel compact formulation of the Tucker integrator, we will further extend the matrix and Tucker projector splitting integrators to the most general class of Tree Tensor Networks. Important examples belonging to this class and of interest for applications are given, but not only restricted to, by Tensor Trains. This seminar is based upon a joint work with Ch. Lubich and H. Walach. Zoom link Add event to Google calendar January 13, 2021 Alexander Viguerie GSSI Efficient, stable, and reliable solvers for the Steady Incompressible Navier-Stokes equations: application to Computational Hemodynamics. Over the past several years, computational fluid dynamics (CFD) simulations have become increasingly popular as a clinical tool for cardiologists at the patient-specific level. The use of CFD in this area poses several challenges. The clinical setting places heavy restrictions on both computational time and power. Simulation results are usually desired within minutes and are usually run on standard computers. For these reasons, steady-state Navier-Stokes simulations are usually preferred, as they can be completed in a fraction of the time required to run an unsteady computation. However, in many respects the steady problem is more difficult than the unsteady one, particularly in regards to solving the associated linear and nonlinear systems. Additionally, boundary data for patient-specific problems is often missing, incomplete, or unreliable. This makes the determination of a useful model challenging, as it requires the generation of reliable boundary data without introducing heavy computational costs. This seminar will address these challenges, as well as some others, and introduce new techniques for workarounds. Results from patient-specific cases will be presented and discussed. Recording of the talk (available to GSSI only) Zoom link Add event to Google calendar December 16, 2020 Martin Stoll TU-Chemnitz From PDEs to data science: an adventure with the graph Laplacian In this talk we briefly review some basic PDE models that are used to model phase separation in materials science. They have since become important tools in image processing and over the last years semi-supervised learning strategies could be implemented with these PDEs at the core. The main ingredient is the graph Laplacian that stems from a graph representation of the data. This matrix is large and typically dense. We illustrate some of its crucial features and show how to efficiently work with the graph Laplacian. In particular, we need some of its eigenvectors and for this the Lanczos process needs to be implemented efficiently. Here, we suggest the use of the NFFT method for evaluating the matrix vector products without even fully constructing the matrix. We illustrate the performance on several examples. Recording of the talk (available to GSSI only) Zoom link Add event to Google calendar December 2, 2020 Patricia Diaz De Alba GSSI Numerical treatment for inverse electromagnetic problems Electromagnetic induction surveys are among the most popular techniques for non-destructive investigation of soil properties, in order to detect the presence of both ground inhomogeneities and particular substances. Frequency-domain electromagnetic instruments allow the collection of data in different configurations, that is, varying the intercoil spacing, the frequency, and the height above the ground. Based on a non-linear forward model used to describe the interaction between an electromagnetic field and the soil, the aim is to reconstruct the distribution of either the electrical conductivity or the magnetic permeability with respect to depth. To this end, the inversion of both the real (in-phase) and the imaginary (quadrature) components of the signal are studied by a regularized damped Gauss-Newton method. The regularization part of the algorithm is based on a low-rank approximation of the Jacobian of the non-linear model. Furthermore, in many situations, a regularization scheme retrieving smooth solutions is blindly applied, without taking into account the prior available knowledge. An algorithm for a regularization method that promotes the sparsity of the reconstructed electrical conductivity or magnetic permeability distribution is available. This regularization strategy incorporates a minimum gradient support stabilizer into a truncated generalized singular value decomposition scheme. The whole inversion algorithm has been enclosed in a MATLAB package, called FDEMtools, allowing the user to experiment with synthetic and experimental data sets, and different regularization strategies, in order to compare them and draw conclusions. The numerical effectiveness of the inversion procedure is demonstrated on synthetic and real datasets by using FDEMtools package. Zoom link Add event to Google calendar November 20, 2020 Christian Lubich University of Tuebingen Dynamical low-rank approximation This talk reviews differential equations and their numerical solution on manifolds of low-rank matrices or of tensors with a rank structure such as tensor trains or general tree tensor networks. These low-rank differential equations serve to approximate, in a data-compressed format, large time-dependent matrices and tensors or multivariate functions that are either given explicitly via their increments or are unknown solutions to high-dimensional evolutionary differential equations, with multi-particle time-dependent Schr\u00f6dinger equations and kinetic equations such as Vlasov equations as noteworthy examples of applications. Recently developed numerical time integrators are based on splitting the projection onto the tangent space of the low-rank manifold at the current approximation. In contrast to all standard integrators, these projector-splitting methods are robust to the unavoidable presence of small singular values in the low-rank approximation. This robustness relies on exploiting geometric properties of the manifold of low-rank matrices or tensors: in each substep of the projector-splitting algorithm, the approximation moves along a flat subspace of the low-rank manifold. In this way, high curvature due to small singular values does no harm. This talk is based on work done intermittently over the last decade with Othmar Koch, Bart Vandereycken, Ivan Oseledets, Emil Kieri, Hanna Walach and Gianluca Ceruti. Zoom link Add event to Google calendar November 18, 2020 Raffaele D'Ambrosio University of L'Aquila Structure-preserving numerics for stochastic differential equations Modern Numerical Analysis is not only devoted to accurately approximating the solutions of various problems through efficient and robust schemes, but also to retaining qualitative properties of the continuous problem over long times. Sometimes such conservation properties naturally characterize the numerical schemes, while in more complex situations preservation issues have to be conveyed into the numerical approximations. The talk is focused on presenting recent advances in structure-preservation issues for selected stochastic differential equations satisfying some characteristic invariance laws. The behaviour of stochastic multistep methods in the preservation of mean-square contractivity will be analyzed; we show, in this case, that conservation properties are hidden, as a matter of fact, into conditional stability properties of numerical schemes. The analysis will also be conveyed to the discretization of stochastic Hamiltonian problems for the numerical preservation of the behaviour of the expected Hamiltonian. The theoretical analysis will also be supported by the numerical evidence. Zoom link Add event to Google calendar November 4, 2020 Giacomo Baggio University of Padua From Model-Based to Data-Driven Control of Network Dynamics The control of complex dynamical networks has attracted increasing interest over the past few years, with reference, in particular, to problems of controllability, optimal input design, and minimal actuator placement. In this talk, I will address the problem of controlling linear dynamical networks from a control-energy or \"practical\" perspective. I will first focus on the model-based scenario and review the fundamental metrics, theoretical limitations, and challenges in controlling networks using a limited number of control nodes. In particular, I will emphasize the impact of the \"degree\" of non-normality of the network's adjacency matrix on the control performance. Then, I will switch to a data-driven scenario, and show how some network control problems can be efficiently solved by relying on experimental data only. Slides of the seminar Zoom link Add event to Google calendar October 14, 2020 Federico Poloni University of Pisa Inverses of quasidefinite matrices in block-factored form, with an application to control theory (joint work with P. Benner) We describe an algorithm to compute the explicit inverse of a dense quasi-definite matrix, i.e., a symmetric matrix of the form [-BB^T, A; A^T, C^TC], with the (1,1) block negative semidefinite and the (2,2) block positive semidefinite. The algorithm is a variant of Gauss-Jordan elimination that works on the low-rank factors $B$ and $C$ directly without ever forming those blocks. The individual elimination steps amount to a transformation called principal pivot transform ; it was shown in [Poloni, Strabic 2016] how to perform it by working only on $A, B, C$, and we rely on that procedure here. We discuss the stability of the resulting method, and show how the algorithm (and in particular the produced low-rank factors) can be of use in control theory, in the context of the matrix sign iteration, which is a method used to solve algebraic Riccati equations. Zoom link Add event to Google calendar September 30, 2020","title":"NOMADS Seminar"},{"location":"vacancies/","text":"Vacancies NEWS We are looking to hire a new colleague at the level of Tenure-Track Assistant Professor to join our group ! We are looking for a new Postodoc to join our group on a project related to Numerics and Machine Learning. This is part of the GSSI-SNS Pro3 grant STANDS, in collaboration with Michele Benzi from the Scuola Normale Superiore in Pisa. More information will be soon posted here. The call for application will open in March 2022. Tenure-Track Assistant Professor Call for Expressions of Interest for a Faculty Position at the level of tenure track Assistant Professor (RTDB) in the Numerical Analysis Group (Math Division) of the Gran Sasso Science Institute, School of Advanced Studies. The Numerical Analysis and Data Science group of the Gran Sasso Science Institute (GSSI) invites expressions of interest for a faculty position at the Assistant Professor level (Tenure Track - RTDB) from highly qualified scholars worldwide. The GSSI Numerical Analysis Division hosts scientists carrying out interdisciplinary research on a variety of subjects, ranging from Matrix Analysis, Numerical ODEs, Numerical PDEs, Dynamical systems, Graph Theory, Numerical Linear Algebra, Computational Network Science and Mathematics of Machine Learning . The GSSI is an International School of Advanced Doctoral Studies, with a prominent program of graduate courses. Located in the city of L\u2019Aquila, in the heart of the Apennine Mountains east of Rome, the institute offers a stimulating environment with numerous PhD students and postdoctoral researchers selected internationally every year. English is the official language for all the activities at the institute (teaching, seminars, tutoring, etc.). About 40 PhD Students in Applied Mathematics from all over the world are at GSSI at any given time, and part of the duties of the Faculty is to provide teaching and supervision of their research activity. Interdisciplinary projects aimed at increasing the connections with other PhD courses at GSSI within the Math Division as well as the other areas (physics, computer science and regional economics) are encouraged. The GSSI plans to announce one tenure-track position in 2022. The present call for expressions of interest is aimed at probing the community of scientists at the international level that might want to join the GSSI faculty. We emphasize that all non-Italian citizens and all Italian candidates having spent sufficient time working abroad are entitled to up to 90% reduction of tax load for at least the first 6 years of employment, as per current Italian regulations. Additionally, the successful candidate will be entitled to up to 30% salary increase with respect to National standards, subject to positive evaluation by the hiring committee. Candidates willing to work in the exciting GSSI atmosphere, as tenure track Assistant Professors, are required to have a doctoral degree in mathematics or related fields prior to the appointment, with a proven record of achievements, a clear potential to promote and lead research activities and a specific interest in teaching at the graduate level to a small set of particularly skilled and motivated students. A curriculum vitae, a list of publications, and a brief research statement should be sent by email ( numerics@gssi.it ), together with a short motivation letter in which the candidate discusses the reasons for their interest in joining the GSSI team. The candidates should also arrange for two recommendation letters to be sent directly to the GSSI ( numerics@gssi.it ), to support their application. The expressions of interest should be sent at your earliest convenience and in any case not later than Jan 31, 2022. GSSI is committed to gender balance, inclusion and diversity. All expressions of interest will be given proper consideration, independent of ethnicity, religion, age, gender, sexual orientation, or disability. PhD students Applications for the PhD program at GSSI open every year around March with several open positions in all the four areas. Deadline for the application is usually in mid June. The PhD program consists of four years with qualifying exams to be taken during the first year. The scholarship for the program offers a monthly salary/stipend, research funds and free housing in institute's residences in the city center of L'Aquila. More details on how to apply can be found here and here .","title":"Join us"},{"location":"vacancies/#vacancies","text":"","title":"Vacancies"},{"location":"vacancies/#news","text":"We are looking to hire a new colleague at the level of Tenure-Track Assistant Professor to join our group ! We are looking for a new Postodoc to join our group on a project related to Numerics and Machine Learning. This is part of the GSSI-SNS Pro3 grant STANDS, in collaboration with Michele Benzi from the Scuola Normale Superiore in Pisa. More information will be soon posted here. The call for application will open in March 2022.","title":"NEWS"},{"location":"vacancies/#tenure-track-assistant-professor","text":"Call for Expressions of Interest for a Faculty Position at the level of tenure track Assistant Professor (RTDB) in the Numerical Analysis Group (Math Division) of the Gran Sasso Science Institute, School of Advanced Studies. The Numerical Analysis and Data Science group of the Gran Sasso Science Institute (GSSI) invites expressions of interest for a faculty position at the Assistant Professor level (Tenure Track - RTDB) from highly qualified scholars worldwide. The GSSI Numerical Analysis Division hosts scientists carrying out interdisciplinary research on a variety of subjects, ranging from Matrix Analysis, Numerical ODEs, Numerical PDEs, Dynamical systems, Graph Theory, Numerical Linear Algebra, Computational Network Science and Mathematics of Machine Learning . The GSSI is an International School of Advanced Doctoral Studies, with a prominent program of graduate courses. Located in the city of L\u2019Aquila, in the heart of the Apennine Mountains east of Rome, the institute offers a stimulating environment with numerous PhD students and postdoctoral researchers selected internationally every year. English is the official language for all the activities at the institute (teaching, seminars, tutoring, etc.). About 40 PhD Students in Applied Mathematics from all over the world are at GSSI at any given time, and part of the duties of the Faculty is to provide teaching and supervision of their research activity. Interdisciplinary projects aimed at increasing the connections with other PhD courses at GSSI within the Math Division as well as the other areas (physics, computer science and regional economics) are encouraged. The GSSI plans to announce one tenure-track position in 2022. The present call for expressions of interest is aimed at probing the community of scientists at the international level that might want to join the GSSI faculty. We emphasize that all non-Italian citizens and all Italian candidates having spent sufficient time working abroad are entitled to up to 90% reduction of tax load for at least the first 6 years of employment, as per current Italian regulations. Additionally, the successful candidate will be entitled to up to 30% salary increase with respect to National standards, subject to positive evaluation by the hiring committee. Candidates willing to work in the exciting GSSI atmosphere, as tenure track Assistant Professors, are required to have a doctoral degree in mathematics or related fields prior to the appointment, with a proven record of achievements, a clear potential to promote and lead research activities and a specific interest in teaching at the graduate level to a small set of particularly skilled and motivated students. A curriculum vitae, a list of publications, and a brief research statement should be sent by email ( numerics@gssi.it ), together with a short motivation letter in which the candidate discusses the reasons for their interest in joining the GSSI team. The candidates should also arrange for two recommendation letters to be sent directly to the GSSI ( numerics@gssi.it ), to support their application. The expressions of interest should be sent at your earliest convenience and in any case not later than Jan 31, 2022. GSSI is committed to gender balance, inclusion and diversity. All expressions of interest will be given proper consideration, independent of ethnicity, religion, age, gender, sexual orientation, or disability.","title":"Tenure-Track Assistant Professor"},{"location":"vacancies/#phd-students","text":"Applications for the PhD program at GSSI open every year around March with several open positions in all the four areas. Deadline for the application is usually in mid June. The PhD program consists of four years with qualifying exams to be taken during the first year. The scholarship for the program offers a monthly salary/stipend, research funds and free housing in institute's residences in the city center of L'Aquila. More details on how to apply can be found here and here .","title":"PhD students"}]}